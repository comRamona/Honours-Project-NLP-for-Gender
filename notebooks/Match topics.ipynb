{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loaded corpus index from /home/ramona/Desktop/Honours-LDA/aan/save/acl_bow10.mm.index\n",
      "initializing corpus reader from /home/ramona/Desktop/Honours-LDA/aan/save/acl_bow10.mm\n",
      "accepted corpus with 22278 documents, 63996 features, 10941296 non-zero entries\n",
      "loading LdaModel object from /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda\n",
      "loading expElogbeta from /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda.expElogbeta.npy with mmap=None\n",
      "loading eta from /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda.eta.npy with mmap=None\n",
      "setting ignored attribute id2word to None\n",
      "setting ignored attribute dispatcher to None\n",
      "setting ignored attribute state to None\n",
      "loaded /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda\n",
      "loading LdaModel object from /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda.state\n",
      "loaded /home/ramona/Desktop/Honours-LDA/aan/save/ldaseed310lda.state\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "built Dictionary(151 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 1 documents (total 151 corpus positions)\n",
      "adding document #0 to Dictionary(151 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(293 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 2 documents (total 302 corpus positions)\n",
      "adding document #0 to Dictionary(293 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(431 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 3 documents (total 453 corpus positions)\n",
      "adding document #0 to Dictionary(431 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(547 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 4 documents (total 604 corpus positions)\n",
      "adding document #0 to Dictionary(547 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(645 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 5 documents (total 755 corpus positions)\n",
      "adding document #0 to Dictionary(645 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(757 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 6 documents (total 906 corpus positions)\n",
      "adding document #0 to Dictionary(757 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(874 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 7 documents (total 1057 corpus positions)\n",
      "adding document #0 to Dictionary(874 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(967 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 8 documents (total 1208 corpus positions)\n",
      "adding document #0 to Dictionary(967 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1061 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 9 documents (total 1359 corpus positions)\n",
      "adding document #0 to Dictionary(1061 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1158 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 10 documents (total 1510 corpus positions)\n",
      "adding document #0 to Dictionary(1158 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1239 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 11 documents (total 1661 corpus positions)\n",
      "adding document #0 to Dictionary(1239 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1312 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 12 documents (total 1812 corpus positions)\n",
      "adding document #0 to Dictionary(1312 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1430 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 13 documents (total 1963 corpus positions)\n",
      "adding document #0 to Dictionary(1430 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1470 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 14 documents (total 2114 corpus positions)\n",
      "adding document #0 to Dictionary(1470 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1539 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 15 documents (total 2265 corpus positions)\n",
      "adding document #0 to Dictionary(1539 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1605 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 16 documents (total 2416 corpus positions)\n",
      "adding document #0 to Dictionary(1605 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1688 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 17 documents (total 2567 corpus positions)\n",
      "adding document #0 to Dictionary(1688 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1754 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 18 documents (total 2718 corpus positions)\n",
      "adding document #0 to Dictionary(1754 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1827 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 19 documents (total 2869 corpus positions)\n",
      "adding document #0 to Dictionary(1827 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1907 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 20 documents (total 3020 corpus positions)\n",
      "adding document #0 to Dictionary(1907 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(1980 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 21 documents (total 3171 corpus positions)\n",
      "adding document #0 to Dictionary(1980 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2033 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 22 documents (total 3322 corpus positions)\n",
      "adding document #0 to Dictionary(2033 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2087 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 23 documents (total 3473 corpus positions)\n",
      "adding document #0 to Dictionary(2087 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2137 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 24 documents (total 3624 corpus positions)\n",
      "adding document #0 to Dictionary(2137 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2187 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 25 documents (total 3775 corpus positions)\n",
      "adding document #0 to Dictionary(2187 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2218 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 26 documents (total 3926 corpus positions)\n",
      "adding document #0 to Dictionary(2218 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2283 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 27 documents (total 4077 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(2283 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2320 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 28 documents (total 4228 corpus positions)\n",
      "adding document #0 to Dictionary(2320 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2388 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 29 documents (total 4379 corpus positions)\n",
      "adding document #0 to Dictionary(2388 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2453 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 30 documents (total 4530 corpus positions)\n",
      "adding document #0 to Dictionary(2453 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2505 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 31 documents (total 4681 corpus positions)\n",
      "adding document #0 to Dictionary(2505 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2555 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 32 documents (total 4832 corpus positions)\n",
      "adding document #0 to Dictionary(2555 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2611 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 33 documents (total 4983 corpus positions)\n",
      "adding document #0 to Dictionary(2611 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2653 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 34 documents (total 5134 corpus positions)\n",
      "adding document #0 to Dictionary(2653 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2803 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 35 documents (total 5285 corpus positions)\n",
      "adding document #0 to Dictionary(2803 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2913 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 36 documents (total 5436 corpus positions)\n",
      "adding document #0 to Dictionary(2913 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(2966 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 37 documents (total 5587 corpus positions)\n",
      "adding document #0 to Dictionary(2966 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3012 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 38 documents (total 5738 corpus positions)\n",
      "adding document #0 to Dictionary(3012 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3156 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 39 documents (total 5889 corpus positions)\n",
      "adding document #0 to Dictionary(3156 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3214 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 40 documents (total 6040 corpus positions)\n",
      "adding document #0 to Dictionary(3214 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3254 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 41 documents (total 6191 corpus positions)\n",
      "adding document #0 to Dictionary(3254 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3292 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 42 documents (total 6342 corpus positions)\n",
      "adding document #0 to Dictionary(3292 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3339 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 43 documents (total 6493 corpus positions)\n",
      "adding document #0 to Dictionary(3339 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3400 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 44 documents (total 6644 corpus positions)\n",
      "adding document #0 to Dictionary(3400 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3457 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 45 documents (total 6795 corpus positions)\n",
      "adding document #0 to Dictionary(3457 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3530 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 46 documents (total 6946 corpus positions)\n",
      "adding document #0 to Dictionary(3530 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3568 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 47 documents (total 7097 corpus positions)\n",
      "adding document #0 to Dictionary(3568 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3609 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 48 documents (total 7248 corpus positions)\n",
      "adding document #0 to Dictionary(3609 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3641 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 49 documents (total 7399 corpus positions)\n",
      "adding document #0 to Dictionary(3641 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3687 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 50 documents (total 7550 corpus positions)\n",
      "adding document #0 to Dictionary(3687 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3721 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 51 documents (total 7701 corpus positions)\n",
      "adding document #0 to Dictionary(3721 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3750 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 52 documents (total 7852 corpus positions)\n",
      "adding document #0 to Dictionary(3750 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3763 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 53 documents (total 8003 corpus positions)\n",
      "adding document #0 to Dictionary(3763 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3814 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 54 documents (total 8154 corpus positions)\n",
      "adding document #0 to Dictionary(3814 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3903 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 55 documents (total 8305 corpus positions)\n",
      "adding document #0 to Dictionary(3903 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(3966 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 56 documents (total 8456 corpus positions)\n",
      "adding document #0 to Dictionary(3966 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4041 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 57 documents (total 8607 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(4041 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4062 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 58 documents (total 8758 corpus positions)\n",
      "adding document #0 to Dictionary(4062 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4090 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 59 documents (total 8909 corpus positions)\n",
      "adding document #0 to Dictionary(4090 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4117 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 60 documents (total 9060 corpus positions)\n",
      "adding document #0 to Dictionary(4117 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4149 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 61 documents (total 9211 corpus positions)\n",
      "adding document #0 to Dictionary(4149 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4197 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 62 documents (total 9362 corpus positions)\n",
      "adding document #0 to Dictionary(4197 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4238 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 63 documents (total 9513 corpus positions)\n",
      "adding document #0 to Dictionary(4238 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4258 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 64 documents (total 9664 corpus positions)\n",
      "adding document #0 to Dictionary(4258 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4298 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 65 documents (total 9815 corpus positions)\n",
      "adding document #0 to Dictionary(4298 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4346 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 66 documents (total 9966 corpus positions)\n",
      "adding document #0 to Dictionary(4346 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4395 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 67 documents (total 10117 corpus positions)\n",
      "adding document #0 to Dictionary(4395 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4435 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 68 documents (total 10268 corpus positions)\n",
      "adding document #0 to Dictionary(4435 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4473 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 69 documents (total 10419 corpus positions)\n",
      "adding document #0 to Dictionary(4473 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4517 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 70 documents (total 10570 corpus positions)\n",
      "adding document #0 to Dictionary(4517 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4555 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 71 documents (total 10721 corpus positions)\n",
      "adding document #0 to Dictionary(4555 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4585 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 72 documents (total 10872 corpus positions)\n",
      "adding document #0 to Dictionary(4585 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4615 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 73 documents (total 11023 corpus positions)\n",
      "adding document #0 to Dictionary(4615 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4688 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 74 documents (total 11174 corpus positions)\n",
      "adding document #0 to Dictionary(4688 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4723 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 75 documents (total 11325 corpus positions)\n",
      "adding document #0 to Dictionary(4723 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4739 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 76 documents (total 11476 corpus positions)\n",
      "adding document #0 to Dictionary(4739 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4775 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 77 documents (total 11627 corpus positions)\n",
      "adding document #0 to Dictionary(4775 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4804 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 78 documents (total 11778 corpus positions)\n",
      "adding document #0 to Dictionary(4804 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4840 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 79 documents (total 11929 corpus positions)\n",
      "adding document #0 to Dictionary(4840 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4871 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 80 documents (total 12080 corpus positions)\n",
      "adding document #0 to Dictionary(4871 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4907 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 81 documents (total 12231 corpus positions)\n",
      "adding document #0 to Dictionary(4907 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4936 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 82 documents (total 12382 corpus positions)\n",
      "adding document #0 to Dictionary(4936 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(4967 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 83 documents (total 12533 corpus positions)\n",
      "adding document #0 to Dictionary(4967 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5006 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 84 documents (total 12684 corpus positions)\n",
      "adding document #0 to Dictionary(5006 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5037 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 85 documents (total 12835 corpus positions)\n",
      "adding document #0 to Dictionary(5037 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5078 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 86 documents (total 12986 corpus positions)\n",
      "adding document #0 to Dictionary(5078 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5198 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 87 documents (total 13137 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(5198 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5298 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 88 documents (total 13288 corpus positions)\n",
      "adding document #0 to Dictionary(5298 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5350 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 89 documents (total 13439 corpus positions)\n",
      "adding document #0 to Dictionary(5350 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5364 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 90 documents (total 13590 corpus positions)\n",
      "adding document #0 to Dictionary(5364 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5390 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 91 documents (total 13741 corpus positions)\n",
      "adding document #0 to Dictionary(5390 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5413 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 92 documents (total 13892 corpus positions)\n",
      "adding document #0 to Dictionary(5413 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5446 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 93 documents (total 14043 corpus positions)\n",
      "adding document #0 to Dictionary(5446 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5457 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 94 documents (total 14194 corpus positions)\n",
      "adding document #0 to Dictionary(5457 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5480 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 95 documents (total 14345 corpus positions)\n",
      "adding document #0 to Dictionary(5480 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5508 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 96 documents (total 14496 corpus positions)\n",
      "adding document #0 to Dictionary(5508 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5532 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 97 documents (total 14647 corpus positions)\n",
      "adding document #0 to Dictionary(5532 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5559 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 98 documents (total 14798 corpus positions)\n",
      "adding document #0 to Dictionary(5559 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5569 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 99 documents (total 14949 corpus positions)\n",
      "adding document #0 to Dictionary(5569 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...)\n",
      "built Dictionary(5577 unique tokens: ['resolution', 'pronoun', 'anaphora', 'antecedent', 'pronouns']...) from 100 documents (total 15100 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Topic 15 #POSTagging 4190 tag pos tagger accuracy tagging tagset noun unknown treebank hmm \n",
      "1 Topic 16 #Dialog 1704 strategy agent evidence conflict proposal accept reject interaction argumentation negotiation \n",
      "2 Topic 81 #LexicalSemantics 2738 message metaphor literal sign activation target metaphorical metonymy actor analogy \n",
      "3 Topic 95 #MachineTranslation(NonStatistical+Bitexts) 3257 translation target translate parallel bilingual corpora monolingual spanish french lingual \n",
      "4 Topic 44 #BiomedicalNamedEntityRecognition 3051 event trigger protein gene extraction entity biomedical genia interaction annotation \n",
      "5 Topic 0 #AnaphoraResolution 1888 mention coreference chain entity resolution link ace head muc document \n",
      "6 Topic 28 #TutoringSystems 2547 response read essay native grade readability reading rater item reader \n",
      "7 Topic 58 #Syntax 2578 marker program element procedure transfer grammar transformation phase noun parse \n",
      "8 Topic 83 #UI/NaturalLanguageInterface 3894 component interface user tool design architecture software display access development \n",
      "9 Topic 90 #LinguisticAnnotation 1370 arabic msa abbreviation dialect habash morphological dialectal write bic diacritic \n",
      "10 Topic 5 #GraphTheory+BioNLP 2576 medical patient disease clinical drug health swedish uml symptom disorder \n",
      "11 Topic 70 #ClassicParsing 3776 grammar parse parser item chart terminal parsing free derivation production \n",
      "12 Topic 46 #FormalComputationalSemantics 1747 representation logical triple ccg learn meaning logic parse composition derivation \n",
      "13 Topic 39 #SyntacticTheory 4647 clause head mwe constituent subject relative complement position construction verb \n",
      "14 Topic 83 #UI/NaturalLanguageInterface 1852 user profile response item request interaction option interactive expert help \n",
      "15 Topic 69 #TreeAdjoiningGrammars  3415 tree node root subtree derivation label leaf child forest parse \n",
      "16 Topic 50 #ChineseKoreanNLP 3412 chinese character segmentation unknown china respectively adopt nese dictionary sequence \n",
      "17 Topic 79 #AlgorithmicEfficiency 2152 precision recall match filter matching run threshold filtering false technique \n",
      "18 Topic 1 #MultiLingualResources 2018 transliteration hindi korean hybrid script name bengali indian target transliterate \n",
      "19 Topic 82 #CollocationsMeasures 2193 candidate gram rank bigram frequency unigram ranking trigram count baseline \n",
      "20 Topic 10 #WebSearch+Wikipedia 1301 category link wikipedia article anchor page categorization wiki title dataset \n",
      "21 Topic 33 #SpeechActs+BDI 3988 action dialog plan goal act belief discourse speaker intention utterance \n",
      "22 Topic 74 #TemporalIE/Aspect 3223 event temporal expression tense interval date past day year reference \n",
      "23 Topic 68 #UnificationBasedGrammars 3461 lexicon entry default lex lexeme sem specification cat unification representation \n",
      "24 Topic 78 #StatisticalMachineTranslation(MorePhraseBased) 3952 translation bleu smt target baseline reordering reorder improvement mos decoder \n",
      "25 Topic 3 #random(commonwords) 3380 meaning interpretation theory representation situation view kind account world involve \n",
      "26 Topic 97 #ProbabilityTheory 4569 probability estimate parameter distribution log likelihood probabilistic estimation equation statistical \n",
      "27 Topic 19 #Morphology 4428 morphological stem suffix morpheme root morphology prefix affix inflection morph \n",
      "28 Topic 28 #TutoringSystems 3758 student expert computer course science learn human computational nlp technology \n",
      "29 Topic 37 #Metrics+HumanEvaluation 3271 metric human reference quality correlation rank judgment automatic judge ranking \n",
      "30 Topic 73 #random(German/Dutch) 4802 german compound der dutch die split splitting component tiger part \n",
      "31 Topic 65 #WordSegmentation 1899 token sequence crf code punctuation field label conditional tokenization quence \n",
      "32 Topic 23 #NamedEntityRecognition 3128 entity name person location ner organization recognition proper ne org \n",
      "33 Topic 79 #AlgorithmicEfficiency 1589 constraint local solution global straint compression ilp solve variable signature \n",
      "34 Topic 92 #WordSenseDisambiguation 4734 sense sens wordnet synset wsd disambiguation target hypernym definition gloss \n",
      "35 Topic 66 #SentimentAnalysis 2450 question answer answering passage ask swer trec factoid return expect \n",
      "36 Topic 96 #TextCategorization 1989 author genre style book email write quote stylistic zone novel \n",
      "37 Topic 54 #random 4310 tile ill tim arc con pro tbr lhe dis mid \n",
      "38 Topic 18 #Multimodal(MainlyGeneration) 4966 object attribute image description visual scene game spatial video expression \n",
      "39 Topic 50 #ChineseKoreanNLP 507 map mapping nil stock market triplet ping key price risk \n",
      "40 Topic 71 #Chunking/MemoryBasedModels 1183 cue detection scope negation detect hedge uncertainty statement certainty detector \n",
      "41 Topic 32 #random(conferenceAndJournalWords) 4608 proceeding university computational conference computer press page science international journal \n",
      "42 Topic 6 #BilingualWordAlignment 4751 alignment align link target ibm position null parallel length aligner \n",
      "43 Topic 22 #random(PronounsCommonnouns) 2056 memory block store stream dynamic change cache array static index \n",
      "44 Topic 80 #SRL/Framenet 1987 argument predicate proposition arg gument position pred obj pr subj \n",
      "45 Topic 85 #ATISdialog 4444 database flight city travel atis subject site query date spoken \n",
      "46 Topic 84 #NeuralNetworks/HumanCognition 1568 network layer neural citation hidden cite deep comparative hide architecture \n",
      "47 Topic 36 #SpeechRecognition 5022 recognition speaker rate error acoustic phone recognizer adaptation hmm vocabulary \n",
      "48 Topic 86 #random(French) 2370 collocation expression french idiom mutual multiword compositional idiomatic meaning que \n",
      "49 Topic 1 #MultiLingualResources 3071 italian spanish distance urdu portuguese variant dutch family guage group \n",
      "50 Topic 90 #LinguisticAnnotation 1137 emotion simplification emotional affect affective anger fear simplify expression song \n",
      "51 Topic 58 #Syntax 2093 gender czech russian person singular pronoun plural male female noun \n",
      "52 Topic 66 #SentimentAnalysis 1833 negative sentiment positive polarity lexicon tweet neutral classification twitter label \n",
      "53 Topic 92 #WordSenseDisambiguation 2209 paraphrase synonym pivot substitution meaning substitute original synonyms resource antonym \n",
      "54 Topic 65 #WordSegmentation 2652 segment segmentation boundary cohesion unit length sequence mentation window segmenter \n",
      "55 Topic 46 #FormalComputationalSemantics 3090 john mary quantifier scope reading operator man causal logical variable \n",
      "56 Topic 53 #MUCEraInformationExtraction 4327 template slot fill object company filler analyst extraction key message \n",
      "57 Topic 22 #random(PronounsCommonnouns) 1735 post tweet social twitter worker thread medium people hit online \n",
      "58 Topic 23 #NamedEntityRecognition 1445 aspect restaurant food ffi lcs hotel extraction component document cluster \n",
      "59 Topic 88 #Collocations/Compounds 1723 hypothesis inference entailment textual rte entail infer challenge exemplar recognize \n",
      "60 Topic 60 #random(misc) 1927 unit module sub incremental thai architecture tts implement ule call \n",
      "61 Topic 14 #SpellCorrection 3141 error correction edit spelling learner preposition rate detect incorrect detection \n",
      "62 Topic 58 #Syntax 2711 noun adjective head compound modifier nominal adj verb determiner modify \n",
      "63 Topic 20 #MachineLearningClassification 2127 kernel svm vector tree svms space bow bag linear representation \n",
      "64 Topic 90 #LinguisticAnnotation 2512 annotation annotator annotate discourse agreement scheme annotated connective label inter \n",
      "65 Topic 0 #AnaphoraResolution 5807 discourse pronoun antecedent resolution referent anaphora reference anaphor anaphoric definite \n",
      "66 Topic 22 #random(PronounsCommonnouns) 1711 child story modality narrative old parent age adult modal acquisition \n",
      "67 Topic 47 #NaturalLanguageGeneration 3269 generation generator content realization choice surface discourse goal rhetorical nlg \n",
      "68 Topic 41 #DiscriminativeSequenceModels 1584 topic document lda distribution topical latent blei dirichlet collection probability \n",
      "69 Topic 66 #SentimentAnalysis 2545 opinion review product target sentiment subjective movie expression subjectivity rating \n",
      "70 Topic 26 #Clustering+DistributionalSimilarity 3084 cluster similarity clustering distance vector dataset weight compute group distributional \n",
      "71 Topic 9 #DocumentRetrieval 2745 document article news keyword collection paragraph title content extraction relevant \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Topic 80 #SRL/Framenet 4513 frame role srl framenet label propbank labeling verb target constituent \n",
      "73 Topic 94 #RelationExtraction 2899 pattern extraction seed learn bootstrapping tern acquire automatically precision acquisition \n",
      "74 Topic 27 #SyntacticTrees 1949 graph node edge path vertex connect link weight arc walk \n",
      "75 Topic 76 #Summarization 3595 summary summarization content human rouge length document automatic tence mary \n",
      "76 Topic 79 #AlgorithmicEfficiency 3278 weight lattice prune decoding beam decode size compute space span \n",
      "77 Topic 1 #MultiLingualResources 1668 lemma gold token share pos predict shared grain team pipeline \n",
      "78 Topic 10 #WebSearch+Wikipedia 2863 dictionary web page google engine entry snippet url collect definition \n",
      "79 Topic 61 #DependencyParsing 3561 dependency parser parse treebank head tree parsing accuracy label constituent \n",
      "80 Topic 42 #LexicalAcquisitionOfVerbSubcategorization 3054 verb subject object construction noun verbal light preposition passive transitive \n",
      "81 Topic 17 #FiniteStateModels(Automata) 3817 string symbol finite transducer transition automaton stack right regular sequence \n",
      "82 Topic 16 #Dialog 4349 dialogue utterance act turn conversation speaker gesture human meeting conversational \n",
      "83 Topic 7 #ConceptOntologies/KnowledgeRep 2932 concept ontology hierarchy conceptual taxonomy definition property cept representation ontological \n",
      "84 Topic 20 #MachineLearningClassification 2900 classifier classification accuracy baseline learn learning decision classify predict prediction \n",
      "85 Topic 9 #DocumentRetrieval 4522 query retrieval document expansion relevant retrieve relevance collection index rank \n",
      "86 Topic 65 #WordSegmentation 1811 chunk fragment stage repair bracket shallow constituent parse partial sequence \n",
      "87 Topic 10 #WebSearch+Wikipedia 3231 resource tool file project format xml element field record database \n",
      "88 Topic 31 #PPAttachment 4049 ambiguity preference disambiguation ambiguous preposition attachment disambiguate heuristic interpretation selectional \n",
      "89 Topic 79 #AlgorithmicEfficiency 2644 length size cost entropy gram vocabulary perplexity oov long normalization \n",
      "90 Topic 21 #JapaneseNLP(notsogood) 3659 japanese expression particle accuracy kanji bunsetsu japan comma fig analyze \n",
      "91 Topic 56 #random 1307 ion t ica ie in i par descr les const \n",
      "92 Topic 26 #Clustering+DistributionalSimilarity 2042 vector space matrix representation dimension embedding similarity lsa dimensional compute \n",
      "93 Topic 62 #Prosody 3438 prosodic speaker asr pause pitch spoken accent transcript transcription duration \n",
      "94 Topic 82 #CollocationsMeasures 3161 frequency occurrence effect association corpora distribution size count item average \n",
      "95 Topic 97 #ProbabilityTheory 2703 distribution sample prior variable latent parameter bayesian inference learn posterior \n",
      "96 Topic 83 #UI/NaturalLanguageInterface 2196 participant action interaction policy subject human instruction condition learn control \n",
      "97 Topic 72 #CategorialGrammar/Logic 3909 definition variable proof logic formula property let condition description axiom \n",
      "98 Topic 55 #ComputationalPhonology 4483 vowel syllable phoneme letter consonant stress phonetic pronunciation phonological sound \n",
      "99 Topic 41 #DiscriminativeSequenceModels 3153 label learn learning supervised unlabeled parameter weight baseline dataset iteration \n"
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import Counter, defaultdict\n",
    "from numpy.random import seed\n",
    "from _storage.storage import FileDir\n",
    "from os.path import join\n",
    "import re\n",
    "from metadata.metadata import ACL_metadata\n",
    "from _topic_modeling.lda_loader import Loader\n",
    "from _storage.storage import FileDir\n",
    "from os.path import join\n",
    "import _pickle as pkl\n",
    "from metadata import Gender\n",
    "import numpy as np\n",
    "import logging\n",
    "import gensim \n",
    "\n",
    "seed(1)\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "def my_dist(v1,v2):\n",
    "    v1 = list(map(lambda x: x[0], v1))\n",
    "    v2 = list(map(lambda x: x[0], v2))\n",
    "    d = 0\n",
    "    n = len(v2)\n",
    "    for i in v1:\n",
    "        if i in v2:\n",
    "            w = n - v2.index(i)\n",
    "            d += w\n",
    "    return d\n",
    "\n",
    "fd = FileDir()\n",
    "loader = Loader()\n",
    "lda = gensim.models.ldamodel.LdaModel.load(join(fd.models, \"ldaseed310lda\"))\n",
    "with open(join(fd.models,\"topic-terms.txt\"),\"r\") as f:\n",
    "    topics = f.read().split(\"\\n\")\n",
    "\n",
    "j_doc_topics = defaultdict(list)\n",
    "j_dic = gensim.corpora.Dictionary()\n",
    "vv = list()\n",
    "for topic in topics:\n",
    "    if len(topic) > 10:\n",
    "        number, name, words = topic.split(\":\")\n",
    "        t = words.strip()\n",
    "        tt = list(map(lambda x: x.strip(), re.split(\"\\\\[0\\\\.\\\\d\\\\d\\\\]\",t)))\n",
    "        if len(tt) == 151:\n",
    "            tt = tt\n",
    "            j_doc_topics[number + name] = tt\n",
    "            j_dic.add_documents([tt])\n",
    "            vv.append(tt)\n",
    "j_topics_bow = defaultdict(list)\n",
    "a = []\n",
    "for i, jbow in j_doc_topics.items():\n",
    "    j_topics_bow[i] = j_dic.doc2bow(jbow)\n",
    "    a.append(j_dic.doc2bow(jbow))\n",
    "    \n",
    "r_doc_topics = defaultdict(list)\n",
    "for t_n in range(100):\n",
    "    for i, p in lda.get_topic_terms(t_n,151):\n",
    "        r_doc_topics[t_n].append(loader.id2word[i])\n",
    "\n",
    "corresp = defaultdict()\n",
    "for i,r in r_doc_topics.items():\n",
    "    r_2bow = j_dic.doc2bow(r)\n",
    "    score = 0\n",
    "    #sims = index[r_2bow]\n",
    "    best_name = \"\"\n",
    "    for name, jt in j_topics_bow.items():\n",
    "        #result = gensim.matutils.cossim(r_2bow, jt)\n",
    "        result = my_dist(r_2bow, jt)\n",
    "        #result = 1 - spatial.distance.cosine(r_2bow, jt)\n",
    "        if(result > score):\n",
    "            best_name = name\n",
    "            score = result\n",
    "    corresp[i] = best_name\n",
    "    x = lda.show_topic(i, 10)\n",
    "    words = \"\"\n",
    "    for w, sc in x:\n",
    "        words += (w + \" \")\n",
    "    print(i, best_name, score, words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Topic 15 #POSTagging 4190 tag pos tagger accuracy tagging tagset noun unknown treebank hmm \n",
      "1 Topic 16 #Dialog 1704 strategy agent evidence conflict proposal accept reject interaction argumentation negotiation \n",
      "2 Topic 81 #LexicalSemantics 2738 message metaphor literal sign activation target metaphorical metonymy actor analogy \n",
      "3 Topic 95 #MachineTranslation(NonStatistical+Bitexts) 3257 translation target translate parallel bilingual corpora monolingual spanish french lingual \n",
      "4 Topic 44 #BiomedicalNamedEntityRecognition 3051 event trigger protein gene extraction entity biomedical genia interaction annotation \n",
      "5 Topic 0 #AnaphoraResolution 1888 mention coreference chain entity resolution link ace head muc document \n",
      "6 Topic 28 #TutoringSystems 2547 response read essay native grade readability reading rater item reader \n",
      "7 Topic 58 #Syntax 2578 marker program element procedure transfer grammar transformation phase noun parse \n",
      "8 Topic 83 #UI/NaturalLanguageInterface 3894 component interface user tool design architecture software display access development \n",
      "9 Topic 90 #LinguisticAnnotation 1370 arabic msa abbreviation dialect habash morphological dialectal write bic diacritic \n",
      "10 Topic 5 #GraphTheory+BioNLP 2576 medical patient disease clinical drug health swedish uml symptom disorder \n",
      "11 Topic 70 #ClassicParsing 3776 grammar parse parser item chart terminal parsing free derivation production \n",
      "12 Topic 46 #FormalComputationalSemantics 1747 representation logical triple ccg learn meaning logic parse composition derivation \n",
      "13 Topic 39 #SyntacticTheory 4647 clause head mwe constituent subject relative complement position construction verb \n",
      "14 Topic 83 #UI/NaturalLanguageInterface 1852 user profile response item request interaction option interactive expert help \n",
      "15 Topic 69 #TreeAdjoiningGrammars  3415 tree node root subtree derivation label leaf child forest parse \n",
      "16 Topic 50 #ChineseKoreanNLP 3412 chinese character segmentation unknown china respectively adopt nese dictionary sequence \n",
      "17 Topic 79 #AlgorithmicEfficiency 2152 precision recall match filter matching run threshold filtering false technique \n",
      "18 Topic 1 #MultiLingualResources 2018 transliteration hindi korean hybrid script name bengali indian target transliterate \n",
      "19 Topic 82 #CollocationsMeasures 2193 candidate gram rank bigram frequency unigram ranking trigram count baseline \n",
      "20 Topic 10 #WebSearch+Wikipedia 1301 category link wikipedia article anchor page categorization wiki title dataset \n",
      "21 Topic 33 #SpeechActs+BDI 3988 action dialog plan goal act belief discourse speaker intention utterance \n",
      "22 Topic 74 #TemporalIE/Aspect 3223 event temporal expression tense interval date past day year reference \n",
      "23 Topic 68 #UnificationBasedGrammars 3461 lexicon entry default lex lexeme sem specification cat unification representation \n",
      "24 Topic 78 #StatisticalMachineTranslation(MorePhraseBased) 3952 translation bleu smt target baseline reordering reorder improvement mos decoder \n",
      "25 Topic 3 #random(commonwords) 3380 meaning interpretation theory representation situation view kind account world involve \n",
      "26 Topic 97 #ProbabilityTheory 4569 probability estimate parameter distribution log likelihood probabilistic estimation equation statistical \n",
      "27 Topic 19 #Morphology 4428 morphological stem suffix morpheme root morphology prefix affix inflection morph \n",
      "28 Topic 28 #TutoringSystems 3758 student expert computer course science learn human computational nlp technology \n",
      "29 Topic 37 #Metrics+HumanEvaluation 3271 metric human reference quality correlation rank judgment automatic judge ranking \n",
      "30 Topic 73 #random(German/Dutch) 4802 german compound der dutch die split splitting component tiger part \n",
      "31 Topic 65 #WordSegmentation 1899 token sequence crf code punctuation field label conditional tokenization quence \n",
      "32 Topic 23 #NamedEntityRecognition 3128 entity name person location ner organization recognition proper ne org \n",
      "33 Topic 79 #AlgorithmicEfficiency 1589 constraint local solution global straint compression ilp solve variable signature \n",
      "34 Topic 92 #WordSenseDisambiguation 4734 sense sens wordnet synset wsd disambiguation target hypernym definition gloss \n",
      "35 Topic 66 #SentimentAnalysis 2450 question answer answering passage ask swer trec factoid return expect \n",
      "36 Topic 96 #TextCategorization 1989 author genre style book email write quote stylistic zone novel \n",
      "37 Topic 54 #random 4310 tile ill tim arc con pro tbr lhe dis mid \n",
      "38 Topic 18 #Multimodal(MainlyGeneration) 4966 object attribute image description visual scene game spatial video expression \n",
      "39 Topic 50 #ChineseKoreanNLP 507 map mapping nil stock market triplet ping key price risk \n",
      "40 Topic 71 #Chunking/MemoryBasedModels 1183 cue detection scope negation detect hedge uncertainty statement certainty detector \n",
      "41 Topic 32 #random(conferenceAndJournalWords) 4608 proceeding university computational conference computer press page science international journal \n",
      "42 Topic 6 #BilingualWordAlignment 4751 alignment align link target ibm position null parallel length aligner \n",
      "43 Topic 22 #random(PronounsCommonnouns) 2056 memory block store stream dynamic change cache array static index \n",
      "44 Topic 80 #SRL/Framenet 1987 argument predicate proposition arg gument position pred obj pr subj \n",
      "45 Topic 85 #ATISdialog 4444 database flight city travel atis subject site query date spoken \n",
      "46 Topic 84 #NeuralNetworks/HumanCognition 1568 network layer neural citation hidden cite deep comparative hide architecture \n",
      "47 Topic 36 #SpeechRecognition 5022 recognition speaker rate error acoustic phone recognizer adaptation hmm vocabulary \n",
      "48 Topic 86 #random(French) 2370 collocation expression french idiom mutual multiword compositional idiomatic meaning que \n",
      "49 Topic 1 #MultiLingualResources 3071 italian spanish distance urdu portuguese variant dutch family guage group \n",
      "50 Topic 90 #LinguisticAnnotation 1137 emotion simplification emotional affect affective anger fear simplify expression song \n",
      "51 Topic 58 #Syntax 2093 gender czech russian person singular pronoun plural male female noun \n",
      "52 Topic 66 #SentimentAnalysis 1833 negative sentiment positive polarity lexicon tweet neutral classification twitter label \n",
      "53 Topic 92 #WordSenseDisambiguation 2209 paraphrase synonym pivot substitution meaning substitute original synonyms resource antonym \n",
      "54 Topic 65 #WordSegmentation 2652 segment segmentation boundary cohesion unit length sequence mentation window segmenter \n",
      "55 Topic 46 #FormalComputationalSemantics 3090 john mary quantifier scope reading operator man causal logical variable \n",
      "56 Topic 53 #MUCEraInformationExtraction 4327 template slot fill object company filler analyst extraction key message \n",
      "57 Topic 22 #random(PronounsCommonnouns) 1735 post tweet social twitter worker thread medium people hit online \n",
      "58 Topic 23 #NamedEntityRecognition 1445 aspect restaurant food ffi lcs hotel extraction component document cluster \n",
      "59 Topic 88 #Collocations/Compounds 1723 hypothesis inference entailment textual rte entail infer challenge exemplar recognize \n",
      "60 Topic 60 #random(misc) 1927 unit module sub incremental thai architecture tts implement ule call \n",
      "61 Topic 14 #SpellCorrection 3141 error correction edit spelling learner preposition rate detect incorrect detection \n",
      "62 Topic 58 #Syntax 2711 noun adjective head compound modifier nominal adj verb determiner modify \n",
      "63 Topic 20 #MachineLearningClassification 2127 kernel svm vector tree svms space bow bag linear representation \n",
      "64 Topic 90 #LinguisticAnnotation 2512 annotation annotator annotate discourse agreement scheme annotated connective label inter \n",
      "65 Topic 0 #AnaphoraResolution 5807 discourse pronoun antecedent resolution referent anaphora reference anaphor anaphoric definite \n",
      "66 Topic 22 #random(PronounsCommonnouns) 1711 child story modality narrative old parent age adult modal acquisition \n",
      "67 Topic 47 #NaturalLanguageGeneration 3269 generation generator content realization choice surface discourse goal rhetorical nlg \n",
      "68 Topic 41 #DiscriminativeSequenceModels 1584 topic document lda distribution topical latent blei dirichlet collection probability \n",
      "69 Topic 66 #SentimentAnalysis 2545 opinion review product target sentiment subjective movie expression subjectivity rating \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Topic 26 #Clustering+DistributionalSimilarity 3084 cluster similarity clustering distance vector dataset weight compute group distributional \n",
      "71 Topic 9 #DocumentRetrieval 2745 document article news keyword collection paragraph title content extraction relevant \n",
      "72 Topic 80 #SRL/Framenet 4513 frame role srl framenet label propbank labeling verb target constituent \n",
      "73 Topic 94 #RelationExtraction 2899 pattern extraction seed learn bootstrapping tern acquire automatically precision acquisition \n",
      "74 Topic 27 #SyntacticTrees 1949 graph node edge path vertex connect link weight arc walk \n",
      "75 Topic 76 #Summarization 3595 summary summarization content human rouge length document automatic tence mary \n",
      "76 Topic 79 #AlgorithmicEfficiency 3278 weight lattice prune decoding beam decode size compute space span \n",
      "77 Topic 1 #MultiLingualResources 1668 lemma gold token share pos predict shared grain team pipeline \n",
      "78 Topic 10 #WebSearch+Wikipedia 2863 dictionary web page google engine entry snippet url collect definition \n",
      "79 Topic 61 #DependencyParsing 3561 dependency parser parse treebank head tree parsing accuracy label constituent \n",
      "80 Topic 42 #LexicalAcquisitionOfVerbSubcategorization 3054 verb subject object construction noun verbal light preposition passive transitive \n",
      "81 Topic 17 #FiniteStateModels(Automata) 3817 string symbol finite transducer transition automaton stack right regular sequence \n",
      "82 Topic 16 #Dialog 4349 dialogue utterance act turn conversation speaker gesture human meeting conversational \n",
      "83 Topic 7 #ConceptOntologies/KnowledgeRep 2932 concept ontology hierarchy conceptual taxonomy definition property cept representation ontological \n",
      "84 Topic 20 #MachineLearningClassification 2900 classifier classification accuracy baseline learn learning decision classify predict prediction \n",
      "85 Topic 9 #DocumentRetrieval 4522 query retrieval document expansion relevant retrieve relevance collection index rank \n",
      "86 Topic 65 #WordSegmentation 1811 chunk fragment stage repair bracket shallow constituent parse partial sequence \n",
      "87 Topic 10 #WebSearch+Wikipedia 3231 resource tool file project format xml element field record database \n",
      "88 Topic 31 #PPAttachment 4049 ambiguity preference disambiguation ambiguous preposition attachment disambiguate heuristic interpretation selectional \n",
      "89 Topic 79 #AlgorithmicEfficiency 2644 length size cost entropy gram vocabulary perplexity oov long normalization \n",
      "90 Topic 21 #JapaneseNLP(notsogood) 3659 japanese expression particle accuracy kanji bunsetsu japan comma fig analyze \n",
      "91 Topic 56 #random 1307 ion t ica ie in i par descr les const \n",
      "92 Topic 26 #Clustering+DistributionalSimilarity 2042 vector space matrix representation dimension embedding similarity lsa dimensional compute \n",
      "93 Topic 62 #Prosody 3438 prosodic speaker asr pause pitch spoken accent transcript transcription duration \n",
      "94 Topic 82 #CollocationsMeasures 3161 frequency occurrence effect association corpora distribution size count item average \n",
      "95 Topic 97 #ProbabilityTheory 2703 distribution sample prior variable latent parameter bayesian inference learn posterior \n",
      "96 Topic 83 #UI/NaturalLanguageInterface 2196 participant action interaction policy subject human instruction condition learn control \n",
      "97 Topic 72 #CategorialGrammar/Logic 3909 definition variable proof logic formula property let condition description axiom \n",
      "98 Topic 55 #ComputationalPhonology 4483 vowel syllable phoneme letter consonant stress phonetic pronunciation phonological sound \n",
      "99 Topic 41 #DiscriminativeSequenceModels 3153 label learn learning supervised unlabeled parameter weight baseline dataset iteration \n"
     ]
    }
   ],
   "source": [
    "for i,r in r_doc_topics.items():\n",
    "    r_2bow = j_dic.doc2bow(r)\n",
    "    score = 0\n",
    "    #sims = index[r_2bow]\n",
    "    best_name = \"\"\n",
    "    for name, jt in j_topics_bow.items():\n",
    "        #result = gensim.matutils.cossim(r_2bow, jt)\n",
    "        result = my_dist(r_2bow, jt)\n",
    "        #result = 1 - spatial.distance.cosine(r_2bow, jt)\n",
    "        if(result > score):\n",
    "            best_name = name\n",
    "            score = result\n",
    "    corresp[i] = best_name\n",
    "    x = lda.show_topic(i, 10)\n",
    "    words = \"\"\n",
    "    for w, sc in x:\n",
    "        words += (w + \" \")\n",
    "    print(i, best_name, score, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.save_pickle(corresp, \"topic_corresp10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = defaultdict(list)\n",
    "for ix, name in corresp.items():\n",
    "    p[name].append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 16 #Dialog [1, 82]\n",
      "[1, 82]\n",
      "1 strategy agent evidence conflict proposal accept reject interaction argumentation negotiation \n",
      "82 dialogue utterance act turn conversation speaker gesture human meeting conversational \n",
      "Topic 0 #AnaphoraResolution [5, 65]\n",
      "[5, 65]\n",
      "5 mention coreference chain entity resolution link ace head muc document \n",
      "65 discourse pronoun antecedent resolution referent anaphora reference anaphor anaphoric definite \n",
      "Topic 28 #TutoringSystems [6, 28]\n",
      "[6, 28]\n",
      "6 response read essay native grade readability reading rater item reader \n",
      "28 student expert computer course science learn human computational nlp technology \n",
      "Topic 58 #Syntax [7, 51, 62]\n",
      "[7, 51, 62]\n",
      "7 marker program element procedure transfer grammar transformation phase noun parse \n",
      "51 gender czech russian person singular pronoun plural male female noun \n",
      "62 noun adjective head compound modifier nominal adj verb determiner modify \n",
      "Topic 83 #UI/NaturalLanguageInterface [8, 14, 96]\n",
      "[8, 14, 96]\n",
      "8 component interface user tool design architecture software display access development \n",
      "14 user profile response item request interaction option interactive expert help \n",
      "96 participant action interaction policy subject human instruction condition learn control \n",
      "Topic 90 #LinguisticAnnotation [9, 64]\n",
      "[9, 64]\n",
      "9 arabic msa abbreviation dialect habash morphological dialectal write bic diacritic \n",
      "64 annotation annotator annotate discourse agreement scheme annotated connective label inter \n",
      "Topic 46 #FormalComputationalSemantics [12, 55]\n",
      "[12, 55]\n",
      "12 representation logical triple ccg learn meaning logic parse composition derivation \n",
      "55 john mary quantifier scope reading operator man causal logical variable \n",
      "Topic 50 #ChineseKoreanNLP [16, 39]\n",
      "[16, 39]\n",
      "16 chinese character segmentation unknown china respectively adopt nese dictionary sequence \n",
      "39 map mapping nil stock market triplet ping key price risk \n",
      "Topic 1 #MultiLingualResources [18, 49, 77]\n",
      "[18, 49, 77]\n",
      "18 transliteration hindi korean hybrid script name bengali indian target transliterate \n",
      "49 italian spanish distance urdu portuguese variant dutch family guage group \n",
      "77 lemma gold token share pos predict shared grain team pipeline \n",
      "Topic 10 #WebSearch+Wikipedia [20, 78, 87]\n",
      "[20, 78, 87]\n",
      "20 category link wikipedia article anchor page categorization wiki title dataset \n",
      "78 dictionary web page google engine entry snippet url collect definition \n",
      "87 resource tool file project format xml element field record database \n",
      "Topic 97 #ProbabilityTheory [26, 95]\n",
      "[26, 95]\n",
      "26 probability estimate parameter distribution log likelihood probabilistic estimation equation statistical \n",
      "95 distribution sample prior variable latent parameter bayesian inference learn posterior \n",
      "Topic 65 #WordSegmentation [31, 54, 86]\n",
      "[31, 54, 86]\n",
      "31 token sequence crf code punctuation field label conditional tokenization quence \n",
      "54 segment segmentation boundary cohesion unit length sequence mentation window segmenter \n",
      "86 chunk fragment stage repair bracket shallow constituent parse partial sequence \n",
      "Topic 23 #NamedEntityRecognition [32, 58]\n",
      "[32, 58]\n",
      "32 entity name person location ner organization recognition proper ne org \n",
      "58 aspect restaurant food ffi lcs hotel extraction component document cluster \n",
      "Topic 92 #WordSenseDisambiguation [34, 53]\n",
      "[34, 53]\n",
      "34 sense sens wordnet synset wsd disambiguation target hypernym definition gloss \n",
      "53 paraphrase synonym pivot substitution meaning substitute original synonyms resource antonym \n",
      "Topic 22 #random(PronounsCommonnouns) [43, 57, 66]\n",
      "[43, 57, 66]\n",
      "43 memory block store stream dynamic change cache array static index \n",
      "57 post tweet social twitter worker thread medium people hit online \n",
      "66 child story modality narrative old parent age adult modal acquisition \n",
      "Topic 80 #SRL/Framenet [44, 72]\n",
      "[44, 72]\n",
      "44 argument predicate proposition arg gument position pred obj pr subj \n",
      "72 frame role srl framenet label propbank labeling verb target constituent \n",
      "Topic 66 #SentimentAnalysis [52, 69]\n",
      "[52, 69]\n",
      "52 negative sentiment positive polarity lexicon tweet neutral classification twitter label \n",
      "69 opinion review product target sentiment subjective movie expression subjectivity rating \n",
      "Topic 20 #MachineLearningClassification [63, 84]\n",
      "[63, 84]\n",
      "63 kernel svm vector tree svms space bow bag linear representation \n",
      "84 classifier classification accuracy baseline learn learning decision classify predict prediction \n",
      "Topic 26 #Clustering+DistributionalSimilarity [70, 92]\n",
      "[70, 92]\n",
      "70 cluster similarity clustering distance vector dataset weight compute group distributional \n",
      "92 vector space matrix representation dimension embedding similarity lsa dimensional compute \n",
      "Topic 9 #DocumentRetrieval [71, 85]\n",
      "[71, 85]\n",
      "71 document article news keyword collection paragraph title content extraction relevant \n",
      "85 query retrieval document expansion relevant retrieve relevance collection index rank \n",
      "Topic 79 #AlgorithmicEfficiency [76, 89]\n",
      "[76, 89]\n",
      "76 weight lattice prune decoding beam decode size compute space span \n",
      "89 length size cost entropy gram vocabulary perplexity oov long normalization \n"
     ]
    }
   ],
   "source": [
    "for name, ixs in q.items():\n",
    "    if(len(ixs) != 1):\n",
    "        print(name, ixs)\n",
    "        print(ixs)\n",
    "        for i in ixs:\n",
    "            x = lda.show_topic(i, 10)\n",
    "            words = \"\"\n",
    "            for w, sc in x:\n",
    "                words += (w + \" \")\n",
    "            print(i, words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "new_corresp = deepcopy(corresp)\n",
    "new_topics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics.append(68)\n",
    "new_corresp[68] = \"TopicModeling\"\n",
    "new_topics.append(68)\n",
    "new_corresp[68] = \"TopicModeling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('map', 0.21350942111785684),\n",
       " ('mapping', 0.2076874090033701),\n",
       " ('nil', 0.028331783240673432),\n",
       " ('stock', 0.02009345345662026),\n",
       " ('market', 0.015021981404966758),\n",
       " ('triplet', 0.013471623057487534),\n",
       " ('ping', 0.012994282415150368),\n",
       " ('key', 0.01249987678565357),\n",
       " ('price', 0.012082976970054842),\n",
       " ('risk', 0.0077979772574410583),\n",
       " ('financial', 0.0069272866858160259),\n",
       " ('chat', 0.0066749036024825875),\n",
       " ('rd', 0.0063560049558132829),\n",
       " ('brand', 0.0060620439509662168),\n",
       " ('stroke', 0.005463469261014718),\n",
       " ('univ', 0.0048751494828098594),\n",
       " ('genotype', 0.0044323600404786957),\n",
       " ('construct', 0.0043401653232380656),\n",
       " ('listing', 0.0038924008255550899),\n",
       " ('phenotype', 0.0037871549884075342)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topic(39,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('probability', 0.093987948990360115),\n",
       " ('estimate', 0.034450078461461128),\n",
       " ('parameter', 0.026355222087439161),\n",
       " ('distribution', 0.016856771738934358),\n",
       " ('log', 0.014157937816928026),\n",
       " ('likelihood', 0.013644350665890002),\n",
       " ('probabilistic', 0.013385955984658247),\n",
       " ('estimation', 0.012626489048246106),\n",
       " ('equation', 0.012408468853758828),\n",
       " ('statistical', 0.010879920904408933),\n",
       " ('compute', 0.010685289791452446),\n",
       " ('maximum', 0.010106574539443349),\n",
       " ('conditional', 0.008501280981230196),\n",
       " ('count', 0.0080470312175654601),\n",
       " ('sequence', 0.0079762955578211968),\n",
       " ('smoothing', 0.0068454659230615762),\n",
       " ('entropy', 0.0065961554417846759),\n",
       " ('weight', 0.0063476394005905759),\n",
       " ('sum', 0.0060456293792374603),\n",
       " ('smooth', 0.0057854499848601091)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topic(26,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('topic', 0.29291134312382872),\n",
       " ('document', 0.03884372624099823),\n",
       " ('lda', 0.033253425301775538),\n",
       " ('distribution', 0.014998211630667776),\n",
       " ('topical', 0.01094035284573555),\n",
       " ('latent', 0.010563181140326968),\n",
       " ('blei', 0.0060659552617144032),\n",
       " ('dirichlet', 0.005860180181647163),\n",
       " ('collection', 0.0054593524168802905),\n",
       " ('probability', 0.0050042094589512953),\n",
       " ('modeling', 0.0047481897126989319),\n",
       " ('denote', 0.0038421847142944571),\n",
       " ('ic', 0.0038306503880666302),\n",
       " ('coherence', 0.0038107611645017535),\n",
       " ('plsa', 0.0038015603873526628),\n",
       " ('dataset', 0.0037875423085469398),\n",
       " ('average', 0.0035598550632339426),\n",
       " ('mixture', 0.003524456758512842),\n",
       " ('vocabulary', 0.0034174157334741569),\n",
       " ('draw', 0.0032759563043510478)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topic(68,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Topic 0 #AnaphoraResolution': [5, 65],\n",
       "             'Topic 1 #MultiLingualResources': [18, 49, 77],\n",
       "             'Topic 10 #WebSearch+Wikipedia': [20, 78, 87],\n",
       "             'Topic 14 #SpellCorrection': [61],\n",
       "             'Topic 15 #POSTagging': [0],\n",
       "             'Topic 16 #Dialog': [1, 82],\n",
       "             'Topic 17 #FiniteStateModels(Automata)': [81],\n",
       "             'Topic 18 #Multimodal(MainlyGeneration)': [38],\n",
       "             'Topic 19 #Morphology': [27],\n",
       "             'Topic 20 #MachineLearningClassification': [63, 84],\n",
       "             'Topic 21 #JapaneseNLP(notsogood)': [90],\n",
       "             'Topic 22 #random(PronounsCommonnouns)': [43, 57, 66],\n",
       "             'Topic 23 #NamedEntityRecognition': [32, 58],\n",
       "             'Topic 26 #Clustering+DistributionalSimilarity': [70, 92],\n",
       "             'Topic 27 #SyntacticTrees': [74],\n",
       "             'Topic 28 #TutoringSystems': [6, 28],\n",
       "             'Topic 3 #random(commonwords)': [25],\n",
       "             'Topic 31 #PPAttachment': [88],\n",
       "             'Topic 32 #random(conferenceAndJournalWords)': [41],\n",
       "             'Topic 33 #SpeechActs+BDI': [21],\n",
       "             'Topic 36 #SpeechRecognition': [47],\n",
       "             'Topic 37 #Metrics+HumanEvaluation': [29],\n",
       "             'Topic 39 #SyntacticTheory': [13],\n",
       "             'Topic 41 #DiscriminativeSequenceModels': [68, 99],\n",
       "             'Topic 42 #LexicalAcquisitionOfVerbSubcategorization': [80],\n",
       "             'Topic 44 #BiomedicalNamedEntityRecognition': [4],\n",
       "             'Topic 46 #FormalComputationalSemantics': [12, 55],\n",
       "             'Topic 47 #NaturalLanguageGeneration': [67],\n",
       "             'Topic 5 #GraphTheory+BioNLP': [10],\n",
       "             'Topic 50 #ChineseKoreanNLP': [16, 39],\n",
       "             'Topic 53 #MUCEraInformationExtraction': [56],\n",
       "             'Topic 54 #random': [37],\n",
       "             'Topic 55 #ComputationalPhonology': [98],\n",
       "             'Topic 56 #random': [91],\n",
       "             'Topic 58 #Syntax': [7, 51, 62],\n",
       "             'Topic 6 #BilingualWordAlignment': [42],\n",
       "             'Topic 60 #random(misc)': [60],\n",
       "             'Topic 61 #DependencyParsing': [79],\n",
       "             'Topic 62 #Prosody': [93],\n",
       "             'Topic 65 #WordSegmentation': [31, 54, 86],\n",
       "             'Topic 66 #SentimentAnalysis': [35, 52, 69],\n",
       "             'Topic 68 #UnificationBasedGrammars': [23],\n",
       "             'Topic 69 #TreeAdjoiningGrammars ': [15],\n",
       "             'Topic 7 #ConceptOntologies/KnowledgeRep': [83],\n",
       "             'Topic 70 #ClassicParsing': [11],\n",
       "             'Topic 71 #Chunking/MemoryBasedModels': [40],\n",
       "             'Topic 72 #CategorialGrammar/Logic': [97],\n",
       "             'Topic 73 #random(German/Dutch)': [30],\n",
       "             'Topic 74 #TemporalIE/Aspect': [22],\n",
       "             'Topic 76 #Summarization': [75],\n",
       "             'Topic 78 #StatisticalMachineTranslation(MorePhraseBased)': [24],\n",
       "             'Topic 79 #AlgorithmicEfficiency': [17, 33, 76, 89],\n",
       "             'Topic 80 #SRL/Framenet': [44, 72],\n",
       "             'Topic 81 #LexicalSemantics': [2],\n",
       "             'Topic 82 #CollocationsMeasures': [19, 94],\n",
       "             'Topic 83 #UI/NaturalLanguageInterface': [8, 14, 96],\n",
       "             'Topic 84 #NeuralNetworks/HumanCognition': [46],\n",
       "             'Topic 85 #ATISdialog': [45],\n",
       "             'Topic 86 #random(French)': [48],\n",
       "             'Topic 88 #Collocations/Compounds': [59],\n",
       "             'Topic 9 #DocumentRetrieval': [71, 85],\n",
       "             'Topic 90 #LinguisticAnnotation': [9, 50, 64],\n",
       "             'Topic 92 #WordSenseDisambiguation': [34, 53],\n",
       "             'Topic 94 #RelationExtraction': [73],\n",
       "             'Topic 95 #MachineTranslation(NonStatistical+Bitexts)': [3],\n",
       "             'Topic 96 #TextCategorization': [36],\n",
       "             'Topic 97 #ProbabilityTheory': [26, 95]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic 11 #AutomataTheory',\n",
       " 'Topic 12 #random(numbers)',\n",
       " 'Topic 13 #random(EvaluativefunctionWords)',\n",
       " 'Topic 2 #random(suffixesprefixes)',\n",
       " 'Topic 24 #FrenchNLP(notsogood)',\n",
       " 'Topic 25 #random',\n",
       " 'Topic 30 #1970s80sNLUWork',\n",
       " 'Topic 34 #random',\n",
       " 'Topic 35 #random',\n",
       " 'Topic 38 #random',\n",
       " 'Topic 4 #LinguisticExampleSentences',\n",
       " 'Topic 40 #DictionaryLexicons',\n",
       " 'Topic 43 #random(experimentation)',\n",
       " 'Topic 45 #random',\n",
       " 'Topic 48 #random(misc)',\n",
       " 'Topic 49 #CoherenceRelations',\n",
       " 'Topic 51 #random(SystemArchitectural)',\n",
       " 'Topic 52 #random(systemDesign)',\n",
       " 'Topic 57 #SpeechParsingAndUnderstanding',\n",
       " 'Topic 59 #Methods(Experimental/Evaluation)',\n",
       " 'Topic 63 #Planning/BDI',\n",
       " 'Topic 64 #StatisticalParsing',\n",
       " 'Topic 67 #random(conferenceWords)',\n",
       " 'Topic 75 #random',\n",
       " 'Topic 77 #Wordnet/MultilinguialOntologies',\n",
       " 'Topic 87 #random(markup)',\n",
       " 'Topic 89 #CodeExamples',\n",
       " 'Topic 91 #random',\n",
       " 'Topic 98 #ReRanking'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = defaultdict(list)\n",
    "for ix, name in new_corresp.items():\n",
    "    q[name].append(ix)\n",
    "set(j_topics_bow.keys()).difference(set(q.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corresp[19] = \"Topic 29 #ngramLanguageModels\"\n",
    "new_corresp[33] = \"Topic 93 #MachineLearningOptimization\"\n",
    "new_corresp[17] = \"Topic 99 #EvaluationMetrics\"\n",
    "new_corresp[35] = \"Topic 8 #QuestionAnsweringDialogSystem(not so good)\"\n",
    "new_corresp[50] = \"Topic 100 #AffectiveComputing\"\n",
    "new_corresp[57] = \"Topic 101 #Twitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.save_pickle(corresp, \"topic_corresp10_edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'Topic 15 #POSTagging'),\n",
       " (1, 'Topic 16 #Dialog'),\n",
       " (2, 'Topic 81 #LexicalSemantics'),\n",
       " (3, 'Topic 95 #MachineTranslation(NonStatistical+Bitexts)'),\n",
       " (4, 'Topic 44 #BiomedicalNamedEntityRecognition'),\n",
       " (5, 'Topic 0 #AnaphoraResolution'),\n",
       " (6, 'Topic 28 #TutoringSystems'),\n",
       " (7, 'Topic 58 #Syntax'),\n",
       " (8, 'Topic 83 #UI/NaturalLanguageInterface'),\n",
       " (9, 'Topic 90 #LinguisticAnnotation'),\n",
       " (10, 'Topic 5 #GraphTheory+BioNLP'),\n",
       " (11, 'Topic 70 #ClassicParsing'),\n",
       " (12, 'Topic 46 #FormalComputationalSemantics'),\n",
       " (13, 'Topic 39 #SyntacticTheory'),\n",
       " (14, 'Topic 83 #UI/NaturalLanguageInterface'),\n",
       " (15, 'Topic 69 #TreeAdjoiningGrammars '),\n",
       " (16, 'Topic 50 #ChineseKoreanNLP'),\n",
       " (17, 'Topic 79 #AlgorithmicEfficiency'),\n",
       " (18, 'Topic 1 #MultiLingualResources'),\n",
       " (19, 'Topic 29 #ngramLanguageModels'),\n",
       " (20, 'Topic 10 #WebSearch+Wikipedia'),\n",
       " (21, 'Topic 33 #SpeechActs+BDI'),\n",
       " (22, 'Topic 74 #TemporalIE/Aspect'),\n",
       " (23, 'Topic 68 #UnificationBasedGrammars'),\n",
       " (24, 'Topic 78 #StatisticalMachineTranslation(MorePhraseBased)'),\n",
       " (25, 'Topic 3 #random(commonwords)'),\n",
       " (26, 'Topic 97 #ProbabilityTheory'),\n",
       " (27, 'Topic 19 #Morphology'),\n",
       " (28, 'Topic 28 #TutoringSystems'),\n",
       " (29, 'Topic 37 #Metrics+HumanEvaluation'),\n",
       " (30, 'Topic 73 #random(German/Dutch)'),\n",
       " (31, 'Topic 65 #WordSegmentation'),\n",
       " (32, 'Topic 23 #NamedEntityRecognition'),\n",
       " (33, 'Topic 79 #AlgorithmicEfficiency'),\n",
       " (34, 'Topic 92 #WordSenseDisambiguation'),\n",
       " (35, 'Topic 66 #SentimentAnalysis'),\n",
       " (36, 'Topic 96 #TextCategorization'),\n",
       " (37, 'Topic 54 #random'),\n",
       " (38, 'Topic 18 #Multimodal(MainlyGeneration)'),\n",
       " (39, 'Topic 50 #ChineseKoreanNLP'),\n",
       " (40, 'Topic 71 #Chunking/MemoryBasedModels'),\n",
       " (41, 'Topic 32 #random(conferenceAndJournalWords)'),\n",
       " (42, 'Topic 6 #BilingualWordAlignment'),\n",
       " (43, 'Topic 22 #random(PronounsCommonnouns)'),\n",
       " (44, 'Topic 80 #SRL/Framenet'),\n",
       " (45, 'Topic 85 #ATISdialog'),\n",
       " (46, 'Topic 84 #NeuralNetworks/HumanCognition'),\n",
       " (47, 'Topic 36 #SpeechRecognition'),\n",
       " (48, 'Topic 86 #random(French)'),\n",
       " (49, 'Topic 1 #MultiLingualResources'),\n",
       " (50, 'Topic 90 #LinguisticAnnotation'),\n",
       " (51, 'Topic 58 #Syntax'),\n",
       " (52, 'Topic 66 #SentimentAnalysis'),\n",
       " (53, 'Topic 92 #WordSenseDisambiguation'),\n",
       " (54, 'Topic 65 #WordSegmentation'),\n",
       " (55, 'Topic 46 #FormalComputationalSemantics'),\n",
       " (56, 'Topic 53 #MUCEraInformationExtraction'),\n",
       " (57, 'Topic 22 #random(PronounsCommonnouns)'),\n",
       " (58, 'Topic 23 #NamedEntityRecognition'),\n",
       " (59, 'Topic 88 #Collocations/Compounds'),\n",
       " (60, 'Topic 60 #random(misc)'),\n",
       " (61, 'Topic 14 #SpellCorrection'),\n",
       " (62, 'Topic 58 #Syntax'),\n",
       " (63, 'Topic 20 #MachineLearningClassification'),\n",
       " (64, 'Topic 90 #LinguisticAnnotation'),\n",
       " (65, 'Topic 0 #AnaphoraResolution'),\n",
       " (66, 'Topic 22 #random(PronounsCommonnouns)'),\n",
       " (67, 'Topic 47 #NaturalLanguageGeneration'),\n",
       " (68, 'TopicModeling'),\n",
       " (69, 'Topic 66 #SentimentAnalysis'),\n",
       " (70, 'Topic 26 #Clustering+DistributionalSimilarity'),\n",
       " (71, 'Topic 9 #DocumentRetrieval'),\n",
       " (72, 'Topic 80 #SRL/Framenet'),\n",
       " (73, 'Topic 94 #RelationExtraction'),\n",
       " (74, 'Topic 27 #SyntacticTrees'),\n",
       " (75, 'Topic 76 #Summarization'),\n",
       " (76, 'Topic 79 #AlgorithmicEfficiency'),\n",
       " (77, 'Topic 1 #MultiLingualResources'),\n",
       " (78, 'Topic 10 #WebSearch+Wikipedia'),\n",
       " (79, 'Topic 61 #DependencyParsing'),\n",
       " (80, 'Topic 42 #LexicalAcquisitionOfVerbSubcategorization'),\n",
       " (81, 'Topic 17 #FiniteStateModels(Automata)'),\n",
       " (82, 'Topic 16 #Dialog'),\n",
       " (83, 'Topic 7 #ConceptOntologies/KnowledgeRep'),\n",
       " (84, 'Topic 20 #MachineLearningClassification'),\n",
       " (85, 'Topic 9 #DocumentRetrieval'),\n",
       " (86, 'Topic 65 #WordSegmentation'),\n",
       " (87, 'Topic 10 #WebSearch+Wikipedia'),\n",
       " (88, 'Topic 31 #PPAttachment'),\n",
       " (89, 'Topic 79 #AlgorithmicEfficiency'),\n",
       " (90, 'Topic 21 #JapaneseNLP(notsogood)'),\n",
       " (91, 'Topic 56 #random'),\n",
       " (92, 'Topic 26 #Clustering+DistributionalSimilarity'),\n",
       " (93, 'Topic 62 #Prosody'),\n",
       " (94, 'Topic 82 #CollocationsMeasures'),\n",
       " (95, 'Topic 97 #ProbabilityTheory'),\n",
       " (96, 'Topic 83 #UI/NaturalLanguageInterface'),\n",
       " (97, 'Topic 72 #CategorialGrammar/Logic'),\n",
       " (98, 'Topic 55 #ComputationalPhonology'),\n",
       " (99, 'Topic 41 #DiscriminativeSequenceModels')}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_corresp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
