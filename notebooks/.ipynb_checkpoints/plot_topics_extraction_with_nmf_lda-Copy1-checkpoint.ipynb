{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "\n",
    "\n",
    "This is an example of applying :class:`sklearn.decomposition.NMF` and\n",
    ":class:`sklearn.decomposition.LatentDirichletAllocation` on a corpus\n",
    "of documents and extract additive models of the topic structure of the\n",
    "corpus.  The output is a list of topics, each represented as a list of\n",
    "terms (weights are not shown).\n",
    "\n",
    "Non-negative Matrix Factorization is applied with two different objective\n",
    "functions: the Frobenius norm, and the generalized Kullback-Leibler divergence.\n",
    "The latter is equivalent to Probabilistic Latent Semantic Indexing.\n",
    "\n",
    "The default parameters (n_samples / n_features / n_components) should make\n",
    "the example runnable in a couple of tens of seconds. You can try to\n",
    "increase the dimensions of the problem, but be aware that the time\n",
    "complexity is polynomial in NMF. In LDA, the time complexity is\n",
    "proportional to (n_samples * iterations).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summa.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import environ\n",
    "import os\n",
    "import logging\n",
    "import _pickle as pkl\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer, word_tokenize\n",
    "import re\n",
    "from metadata import metadata\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import langid\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import gensim\n",
    "\n",
    "rng = np.random.RandomState(10102016)\n",
    "np.random.seed(18101995)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers = [logging.StreamHandler()]\n",
    "import datetime\n",
    "\n",
    "def dehyphenate(s):\n",
    "    return s.replace('-\\n','').lower()\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "def psave(ob, filename, timestamp = False):\n",
    "    timenow = \"\"\n",
    "    if timestamp:\n",
    "        timenow = '{:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    with(open(\"../models/\" + filename + timenow,\"wb\")) as f:\n",
    "        pkl.dump(ob,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "with open( os.path.join(os.environ[\"AAN_DIR\"],\"papers_text/{0}\".format(\"W04-0203.txt\"))) as f:\n",
    "    good_text  = f.read().replace('-\\n','')\n",
    "with open( os.path.join(os.environ[\"AAN_DIR\"],\"papers_text/{0}\".format(\"W04-0207.txt\"))) as f:\n",
    "    good_text2  = f.read().replace('-\\n','')\n",
    "with open( os.path.join(os.environ[\"AAN_DIR\"],\"papers_text/{0}\".format(\"W04-0205.txt\"))) as f:\n",
    "    bad_text  = f.read().replace('-\\n','')\n",
    "with open( os.path.join(os.environ[\"AAN_DIR\"],\"papers_text/{0}\".format(\"J79-1011.txt\"))) as f:\n",
    "    bad_text2 = f.read().replace('-\\n','')   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata.metadata import ACL_metadata\n",
    "acl = ACL_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>genders</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E03-1001</th>\n",
       "      <td>[Oard,Douglasw]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Multilingual Access To Large Spoken Archives (...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1002</th>\n",
       "      <td>[Henderson,Jamesb]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Neural Network Probability Estimation For Broa...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1003</th>\n",
       "      <td>[Burstein,Jill, Wolska,Magdalena]</td>\n",
       "      <td>[Gender.female, Gender.female]</td>\n",
       "      <td>Toward Evaluation Of Writing Style: Overly Rep...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1004</th>\n",
       "      <td>[Cmejrek,Martin, Curin,Jan, Havelka,Jiri]</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male]</td>\n",
       "      <td>Czech-English Dependency Tree-Based Machine Tr...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1005</th>\n",
       "      <td>[Bod,Rens]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>An Efficient Implementation Of A New DOP Model</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1006</th>\n",
       "      <td>[Smets,Martine, Gamon,Michael, Corstonoliver,S...</td>\n",
       "      <td>[Gender.female, Gender.male, Gender.male, Gend...</td>\n",
       "      <td>French Amalgam: A Quick Adaptation Of A Senten...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1007</th>\n",
       "      <td>[Ueffing,Nicola, Ney,Hermann]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Using POS Information For SMT Into Morphologic...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1008</th>\n",
       "      <td>[Steedman,Mark, Osborne,Miles, Sarkar,Anoop, C...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Bootstrapping Statistical Parsers From Small D...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1009</th>\n",
       "      <td>[Clark,Alexander]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Combining Distributional And Morphological Inf...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1010</th>\n",
       "      <td>[Yasuda,Keiji, Sugaya,Fumiaki, Takezawa,Toshiy...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Automatic Evaluation For A Palpable Measure Of...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1011</th>\n",
       "      <td>[Dingli,Alexiei, Ciravegna,Fabio, Guthrie,Davi...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Mining Web Sites Using Unsupervised Adaptive I...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1012</th>\n",
       "      <td>[Alexin,Zoltan, Gyimothy,Tibor, Hatvani,Csaba,...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Manually Annotated Hungarian Corpus</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1013</th>\n",
       "      <td>[Hosaka,Junko, Koh,Judice, Konagaya,Akihiko]</td>\n",
       "      <td>[Gender.female, Gender.female, Gender.male]</td>\n",
       "      <td>Effect Of Utilizing Terminology On Extraction ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1014</th>\n",
       "      <td>[Zabokrtsky,Zdenek, Smrz,Otakar]</td>\n",
       "      <td>[Gender.male, Gender.male]</td>\n",
       "      <td>Arabic Syntactic Trees: From Constituency To D...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1015</th>\n",
       "      <td>[Poibeau,Thierry]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>The Multilingual Named Entity Recognition Fram...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1017</th>\n",
       "      <td>[Horacek,Helmut]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>A Best-First Search Algorithm For Generating R...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1018</th>\n",
       "      <td>[Bentivogli,Luisa, Pianta,Emanuele]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Beyond Lexical Units: Enriching WordNets With ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1019</th>\n",
       "      <td>[Piwek,Paul]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>A Flexible Pragmatics-Driven Language Generato...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1020</th>\n",
       "      <td>[Dorow,Beate, Widdows,Dominic]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Discovering Corpus-Specific Word Senses</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1021</th>\n",
       "      <td>[Sripada,Somayajulug, Reiter,Ehud, Hunter,Jim,...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Summarizing Neonatal Time Series Data</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1022</th>\n",
       "      <td>[Nerima,Luka, Seretan,Violeta, Wehrli,Eric]</td>\n",
       "      <td>[Gender.male, Gender.female, Gender.male]</td>\n",
       "      <td>Creating A Multilingual Collocations Dictionar...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1023</th>\n",
       "      <td>[Utsuro,Takehito, Horiuchi,Takashi, Hamamoto,T...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Effect Of Cross-Language IR In Bilingual Lexic...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1024</th>\n",
       "      <td>[Koller,Alexander, Niehren,Joachim, Thater,Ste...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male]</td>\n",
       "      <td>Underspecification Formalisms: Hole Semantics ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1025</th>\n",
       "      <td>[Preiss,Judita]</td>\n",
       "      <td>[Gender.female]</td>\n",
       "      <td>Using Grammatical Relations To Compare Parsers</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1026</th>\n",
       "      <td>[Tiedemann,Jorg]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Combining Clues For Word Alignment</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1027</th>\n",
       "      <td>[Erk,Katrin, Niehren,Joachim]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Well-Nested Parallelism Constraints For Ellips...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1028</th>\n",
       "      <td>[Penn,Gerald]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>AVM Description Compilation Using Types As Modes</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1029</th>\n",
       "      <td>[Imamura,Kenji, Sumita,Eiichiro, Matsumoto,Yuji]</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male]</td>\n",
       "      <td>Automatic Construction Of Machine Translation ...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1030</th>\n",
       "      <td>[Gardent,Claire, Kallmeyer,Laura]</td>\n",
       "      <td>[Gender.female, Gender.female]</td>\n",
       "      <td>Semantic Construction In F-TAG</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E03-1031</th>\n",
       "      <td>[Ylijyra,Anssi]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Describing Syntax With Star-Free Regular Expre...</td>\n",
       "      <td>EACL</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3912</th>\n",
       "      <td>[King,Levi, Baucom,Eric, Gilmanov,Timur, Kuble...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>The IUCL+ System: Word-Level Language Identifi...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3913</th>\n",
       "      <td>[Carpuat,Marine]</td>\n",
       "      <td>[Gender.female]</td>\n",
       "      <td>Mixed Language and Code-Switching in the Canad...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3914</th>\n",
       "      <td>[Bali,Kalika, Sharma,Jatin, Choudhury,Monojit,...</td>\n",
       "      <td>[Gender.female, Gender.male, Gender.male, Gend...</td>\n",
       "      <td>I am borrowing ya mixing ? An Analysis of Engl...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3915</th>\n",
       "      <td>[Barman,Utsab, Wagner,Joachim, Chrupala,Grzego...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>DCU-UVT: Word-Level Language Classification wi...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3916</th>\n",
       "      <td>[Shrestha,Prajwol]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Incremental N-gram Approach for Language Ident...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-3917</th>\n",
       "      <td>[Bar,Kfir, Dershowitz,Nachum]</td>\n",
       "      <td>[Gender.male, Gender.male]</td>\n",
       "      <td>The Tel Aviv University System for the Code-Sw...</td>\n",
       "      <td>Workshop on Computational Approaches to Code S...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4101</th>\n",
       "      <td>[Wise,Alyssa]</td>\n",
       "      <td>[Gender.female]</td>\n",
       "      <td>Keynote: Data Archeology: A theory informed ap...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4102</th>\n",
       "      <td>[Sinha,Tanmay, Jermann,Patrick, Li,Nan, Dillen...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.unknown, Gen...</td>\n",
       "      <td>Your click decides your fate: Inferring Inform...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4103</th>\n",
       "      <td>[Moon,Seungwhan, Potdar,Saloni, Martin,Lara]</td>\n",
       "      <td>[Gender.unknown, Gender.female, Gender.female]</td>\n",
       "      <td>Identifying Student Leaders from MOOC Discussi...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4104</th>\n",
       "      <td>[Yang,Diyi, Wen,Miaomiao, Rose,Carolyn]</td>\n",
       "      <td>[Gender.female, Gender.female, Gender.female]</td>\n",
       "      <td>Towards Identifying the Resolvability of Threa...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4105</th>\n",
       "      <td>[Elouazizi,Noureddine]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Point-of-View Mining and Cognitive Presence in...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4106</th>\n",
       "      <td>[Jermann,Patrick]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Keynote Talk: Analytics: climbing up the ladde...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4107</th>\n",
       "      <td>[Rose,Carolyn, Siemens,George]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Shared Task on Prediction of Dropout Over Time...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4108</th>\n",
       "      <td>[Sinha,Tanmay, Li,Nan, Jermann,Patrick, Dillen...</td>\n",
       "      <td>[Gender.male, Gender.unknown, Gender.male, Gen...</td>\n",
       "      <td>Capturing attrition intensifying structural tr...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4109</th>\n",
       "      <td>[Sharkey,Mike, Sanders,Robert]</td>\n",
       "      <td>[Gender.male, Gender.male]</td>\n",
       "      <td>A Process for Predicting MOOC Attrition</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4110</th>\n",
       "      <td>[Amnueypornsakul,Bussaba, Bhat,Suma, Chinprutt...</td>\n",
       "      <td>[Gender.female, Gender.female, Gender.male]</td>\n",
       "      <td>Predicting Attrition Along the Way: The UIUC M...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4111</th>\n",
       "      <td>[Kloft,Marius, Stiehler,Felix, Zheng,Zhilin, P...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Predicting MOOC Dropout over Weeks Using Machi...</td>\n",
       "      <td>Workshop on Analysis of Large Scale Social Int...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4201</th>\n",
       "      <td>[Habash,Nizar]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>INVITED TALK 1: Computational Processing of Ar...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4202</th>\n",
       "      <td>[Kanayama,Hiroshi, Park,Youngja, Tsuboi,Yuta, ...</td>\n",
       "      <td>[Gender.male, Gender.female, Gender.male, Gend...</td>\n",
       "      <td>Learning from a Neighbor: Adapting a Japanese ...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4203</th>\n",
       "      <td>[Agic,Zeljko, Agic,Zeljko, Tiedemann,Jorg, Mer...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Cross-lingual Dependency Parsing of Related La...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4204</th>\n",
       "      <td>[Maier,Wolfgang, Gomezrodriguez,Carlos]</td>\n",
       "      <td>[Gender.male, Gender.male]</td>\n",
       "      <td>Language variety identification in Spanish tweets</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4205</th>\n",
       "      <td>[Abbas,Qaiser]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>Exploiting Language Variants Via Grammar Parsi...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4206</th>\n",
       "      <td>[Bhat,Riyazahmad, Jain,Naman, Vaidya,Ashwini, ...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.female, Gend...</td>\n",
       "      <td>Adapting Predicate Frames for Urdu PropBanking</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4207</th>\n",
       "      <td>[Nouri,Javad, Yangarber,Roman]</td>\n",
       "      <td>[Gender.male, Gender.male]</td>\n",
       "      <td>Measuring Language Closeness by Modeling Regul...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4208</th>\n",
       "      <td>[Petrov,Slav]</td>\n",
       "      <td>[Gender.male]</td>\n",
       "      <td>INVITED TALK 2: Towards Universal Syntactic Pr...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4209</th>\n",
       "      <td>[Miyazaki,Taro, Kato,Naoto, Inoue,Seiki, Umeda...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Proper Name Machine Translation from Japanese ...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4210</th>\n",
       "      <td>[Popovic,Maja, Ljubesic,Nikola]</td>\n",
       "      <td>[Gender.female, Gender.male]</td>\n",
       "      <td>Exploring cross-language statistical machine t...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4211</th>\n",
       "      <td>[Singla,Karan, Singh,Anupam, Shastri,Nishkarsh...</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male, Gender...</td>\n",
       "      <td>Exploring System Combination approaches for In...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4212</th>\n",
       "      <td>[Kubon,Vladislav, Kubon,Vladislav, Vicic,Jernej]</td>\n",
       "      <td>[Gender.male, Gender.male, Gender.male]</td>\n",
       "      <td>A Comparison of MT Methods for Closely Related...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W14-4213</th>\n",
       "      <td>[Aminian,Maryam, Ghoneim,Mahmoud, Diab,Mona]</td>\n",
       "      <td>[Gender.female, Gender.male, Gender.female]</td>\n",
       "      <td>Handling OOV Words in Dialectal Arabic to Engl...</td>\n",
       "      <td>LT4CloseLang</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23766 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    authors  \\\n",
       "id                                                            \n",
       "E03-1001                                    [Oard,Douglasw]   \n",
       "E03-1002                                 [Henderson,Jamesb]   \n",
       "E03-1003                  [Burstein,Jill, Wolska,Magdalena]   \n",
       "E03-1004          [Cmejrek,Martin, Curin,Jan, Havelka,Jiri]   \n",
       "E03-1005                                         [Bod,Rens]   \n",
       "E03-1006  [Smets,Martine, Gamon,Michael, Corstonoliver,S...   \n",
       "E03-1007                      [Ueffing,Nicola, Ney,Hermann]   \n",
       "E03-1008  [Steedman,Mark, Osborne,Miles, Sarkar,Anoop, C...   \n",
       "E03-1009                                  [Clark,Alexander]   \n",
       "E03-1010  [Yasuda,Keiji, Sugaya,Fumiaki, Takezawa,Toshiy...   \n",
       "E03-1011  [Dingli,Alexiei, Ciravegna,Fabio, Guthrie,Davi...   \n",
       "E03-1012  [Alexin,Zoltan, Gyimothy,Tibor, Hatvani,Csaba,...   \n",
       "E03-1013       [Hosaka,Junko, Koh,Judice, Konagaya,Akihiko]   \n",
       "E03-1014                   [Zabokrtsky,Zdenek, Smrz,Otakar]   \n",
       "E03-1015                                  [Poibeau,Thierry]   \n",
       "E03-1017                                   [Horacek,Helmut]   \n",
       "E03-1018                [Bentivogli,Luisa, Pianta,Emanuele]   \n",
       "E03-1019                                       [Piwek,Paul]   \n",
       "E03-1020                     [Dorow,Beate, Widdows,Dominic]   \n",
       "E03-1021  [Sripada,Somayajulug, Reiter,Ehud, Hunter,Jim,...   \n",
       "E03-1022        [Nerima,Luka, Seretan,Violeta, Wehrli,Eric]   \n",
       "E03-1023  [Utsuro,Takehito, Horiuchi,Takashi, Hamamoto,T...   \n",
       "E03-1024  [Koller,Alexander, Niehren,Joachim, Thater,Ste...   \n",
       "E03-1025                                    [Preiss,Judita]   \n",
       "E03-1026                                   [Tiedemann,Jorg]   \n",
       "E03-1027                      [Erk,Katrin, Niehren,Joachim]   \n",
       "E03-1028                                      [Penn,Gerald]   \n",
       "E03-1029   [Imamura,Kenji, Sumita,Eiichiro, Matsumoto,Yuji]   \n",
       "E03-1030                  [Gardent,Claire, Kallmeyer,Laura]   \n",
       "E03-1031                                    [Ylijyra,Anssi]   \n",
       "...                                                     ...   \n",
       "W14-3912  [King,Levi, Baucom,Eric, Gilmanov,Timur, Kuble...   \n",
       "W14-3913                                   [Carpuat,Marine]   \n",
       "W14-3914  [Bali,Kalika, Sharma,Jatin, Choudhury,Monojit,...   \n",
       "W14-3915  [Barman,Utsab, Wagner,Joachim, Chrupala,Grzego...   \n",
       "W14-3916                                 [Shrestha,Prajwol]   \n",
       "W14-3917                      [Bar,Kfir, Dershowitz,Nachum]   \n",
       "W14-4101                                      [Wise,Alyssa]   \n",
       "W14-4102  [Sinha,Tanmay, Jermann,Patrick, Li,Nan, Dillen...   \n",
       "W14-4103       [Moon,Seungwhan, Potdar,Saloni, Martin,Lara]   \n",
       "W14-4104            [Yang,Diyi, Wen,Miaomiao, Rose,Carolyn]   \n",
       "W14-4105                             [Elouazizi,Noureddine]   \n",
       "W14-4106                                  [Jermann,Patrick]   \n",
       "W14-4107                     [Rose,Carolyn, Siemens,George]   \n",
       "W14-4108  [Sinha,Tanmay, Li,Nan, Jermann,Patrick, Dillen...   \n",
       "W14-4109                     [Sharkey,Mike, Sanders,Robert]   \n",
       "W14-4110  [Amnueypornsakul,Bussaba, Bhat,Suma, Chinprutt...   \n",
       "W14-4111  [Kloft,Marius, Stiehler,Felix, Zheng,Zhilin, P...   \n",
       "W14-4201                                     [Habash,Nizar]   \n",
       "W14-4202  [Kanayama,Hiroshi, Park,Youngja, Tsuboi,Yuta, ...   \n",
       "W14-4203  [Agic,Zeljko, Agic,Zeljko, Tiedemann,Jorg, Mer...   \n",
       "W14-4204            [Maier,Wolfgang, Gomezrodriguez,Carlos]   \n",
       "W14-4205                                     [Abbas,Qaiser]   \n",
       "W14-4206  [Bhat,Riyazahmad, Jain,Naman, Vaidya,Ashwini, ...   \n",
       "W14-4207                     [Nouri,Javad, Yangarber,Roman]   \n",
       "W14-4208                                      [Petrov,Slav]   \n",
       "W14-4209  [Miyazaki,Taro, Kato,Naoto, Inoue,Seiki, Umeda...   \n",
       "W14-4210                    [Popovic,Maja, Ljubesic,Nikola]   \n",
       "W14-4211  [Singla,Karan, Singh,Anupam, Shastri,Nishkarsh...   \n",
       "W14-4212   [Kubon,Vladislav, Kubon,Vladislav, Vicic,Jernej]   \n",
       "W14-4213       [Aminian,Maryam, Ghoneim,Mahmoud, Diab,Mona]   \n",
       "\n",
       "                                                    genders  \\\n",
       "id                                                            \n",
       "E03-1001                                      [Gender.male]   \n",
       "E03-1002                                      [Gender.male]   \n",
       "E03-1003                     [Gender.female, Gender.female]   \n",
       "E03-1004            [Gender.male, Gender.male, Gender.male]   \n",
       "E03-1005                                      [Gender.male]   \n",
       "E03-1006  [Gender.female, Gender.male, Gender.male, Gend...   \n",
       "E03-1007                       [Gender.female, Gender.male]   \n",
       "E03-1008  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1009                                      [Gender.male]   \n",
       "E03-1010  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1011  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1012  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1013        [Gender.female, Gender.female, Gender.male]   \n",
       "E03-1014                         [Gender.male, Gender.male]   \n",
       "E03-1015                                      [Gender.male]   \n",
       "E03-1017                                      [Gender.male]   \n",
       "E03-1018                       [Gender.female, Gender.male]   \n",
       "E03-1019                                      [Gender.male]   \n",
       "E03-1020                       [Gender.female, Gender.male]   \n",
       "E03-1021  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1022          [Gender.male, Gender.female, Gender.male]   \n",
       "E03-1023  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "E03-1024            [Gender.male, Gender.male, Gender.male]   \n",
       "E03-1025                                    [Gender.female]   \n",
       "E03-1026                                      [Gender.male]   \n",
       "E03-1027                       [Gender.female, Gender.male]   \n",
       "E03-1028                                      [Gender.male]   \n",
       "E03-1029            [Gender.male, Gender.male, Gender.male]   \n",
       "E03-1030                     [Gender.female, Gender.female]   \n",
       "E03-1031                                      [Gender.male]   \n",
       "...                                                     ...   \n",
       "W14-3912  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-3913                                    [Gender.female]   \n",
       "W14-3914  [Gender.female, Gender.male, Gender.male, Gend...   \n",
       "W14-3915  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-3916                                      [Gender.male]   \n",
       "W14-3917                         [Gender.male, Gender.male]   \n",
       "W14-4101                                    [Gender.female]   \n",
       "W14-4102  [Gender.male, Gender.male, Gender.unknown, Gen...   \n",
       "W14-4103     [Gender.unknown, Gender.female, Gender.female]   \n",
       "W14-4104      [Gender.female, Gender.female, Gender.female]   \n",
       "W14-4105                                      [Gender.male]   \n",
       "W14-4106                                      [Gender.male]   \n",
       "W14-4107                       [Gender.female, Gender.male]   \n",
       "W14-4108  [Gender.male, Gender.unknown, Gender.male, Gen...   \n",
       "W14-4109                         [Gender.male, Gender.male]   \n",
       "W14-4110        [Gender.female, Gender.female, Gender.male]   \n",
       "W14-4111  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-4201                                      [Gender.male]   \n",
       "W14-4202  [Gender.male, Gender.female, Gender.male, Gend...   \n",
       "W14-4203  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-4204                         [Gender.male, Gender.male]   \n",
       "W14-4205                                      [Gender.male]   \n",
       "W14-4206  [Gender.male, Gender.male, Gender.female, Gend...   \n",
       "W14-4207                         [Gender.male, Gender.male]   \n",
       "W14-4208                                      [Gender.male]   \n",
       "W14-4209  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-4210                       [Gender.female, Gender.male]   \n",
       "W14-4211  [Gender.male, Gender.male, Gender.male, Gender...   \n",
       "W14-4212            [Gender.male, Gender.male, Gender.male]   \n",
       "W14-4213        [Gender.female, Gender.male, Gender.female]   \n",
       "\n",
       "                                                      title  \\\n",
       "id                                                            \n",
       "E03-1001  Multilingual Access To Large Spoken Archives (...   \n",
       "E03-1002  Neural Network Probability Estimation For Broa...   \n",
       "E03-1003  Toward Evaluation Of Writing Style: Overly Rep...   \n",
       "E03-1004  Czech-English Dependency Tree-Based Machine Tr...   \n",
       "E03-1005     An Efficient Implementation Of A New DOP Model   \n",
       "E03-1006  French Amalgam: A Quick Adaptation Of A Senten...   \n",
       "E03-1007  Using POS Information For SMT Into Morphologic...   \n",
       "E03-1008  Bootstrapping Statistical Parsers From Small D...   \n",
       "E03-1009  Combining Distributional And Morphological Inf...   \n",
       "E03-1010  Automatic Evaluation For A Palpable Measure Of...   \n",
       "E03-1011  Mining Web Sites Using Unsupervised Adaptive I...   \n",
       "E03-1012                Manually Annotated Hungarian Corpus   \n",
       "E03-1013  Effect Of Utilizing Terminology On Extraction ...   \n",
       "E03-1014  Arabic Syntactic Trees: From Constituency To D...   \n",
       "E03-1015  The Multilingual Named Entity Recognition Fram...   \n",
       "E03-1017  A Best-First Search Algorithm For Generating R...   \n",
       "E03-1018  Beyond Lexical Units: Enriching WordNets With ...   \n",
       "E03-1019  A Flexible Pragmatics-Driven Language Generato...   \n",
       "E03-1020            Discovering Corpus-Specific Word Senses   \n",
       "E03-1021              Summarizing Neonatal Time Series Data   \n",
       "E03-1022  Creating A Multilingual Collocations Dictionar...   \n",
       "E03-1023  Effect Of Cross-Language IR In Bilingual Lexic...   \n",
       "E03-1024  Underspecification Formalisms: Hole Semantics ...   \n",
       "E03-1025     Using Grammatical Relations To Compare Parsers   \n",
       "E03-1026                 Combining Clues For Word Alignment   \n",
       "E03-1027  Well-Nested Parallelism Constraints For Ellips...   \n",
       "E03-1028   AVM Description Compilation Using Types As Modes   \n",
       "E03-1029  Automatic Construction Of Machine Translation ...   \n",
       "E03-1030                     Semantic Construction In F-TAG   \n",
       "E03-1031  Describing Syntax With Star-Free Regular Expre...   \n",
       "...                                                     ...   \n",
       "W14-3912  The IUCL+ System: Word-Level Language Identifi...   \n",
       "W14-3913  Mixed Language and Code-Switching in the Canad...   \n",
       "W14-3914  I am borrowing ya mixing ? An Analysis of Engl...   \n",
       "W14-3915  DCU-UVT: Word-Level Language Classification wi...   \n",
       "W14-3916  Incremental N-gram Approach for Language Ident...   \n",
       "W14-3917  The Tel Aviv University System for the Code-Sw...   \n",
       "W14-4101  Keynote: Data Archeology: A theory informed ap...   \n",
       "W14-4102  Your click decides your fate: Inferring Inform...   \n",
       "W14-4103  Identifying Student Leaders from MOOC Discussi...   \n",
       "W14-4104  Towards Identifying the Resolvability of Threa...   \n",
       "W14-4105  Point-of-View Mining and Cognitive Presence in...   \n",
       "W14-4106  Keynote Talk: Analytics: climbing up the ladde...   \n",
       "W14-4107  Shared Task on Prediction of Dropout Over Time...   \n",
       "W14-4108  Capturing attrition intensifying structural tr...   \n",
       "W14-4109            A Process for Predicting MOOC Attrition   \n",
       "W14-4110  Predicting Attrition Along the Way: The UIUC M...   \n",
       "W14-4111  Predicting MOOC Dropout over Weeks Using Machi...   \n",
       "W14-4201  INVITED TALK 1: Computational Processing of Ar...   \n",
       "W14-4202  Learning from a Neighbor: Adapting a Japanese ...   \n",
       "W14-4203  Cross-lingual Dependency Parsing of Related La...   \n",
       "W14-4204  Language variety identification in Spanish tweets   \n",
       "W14-4205  Exploiting Language Variants Via Grammar Parsi...   \n",
       "W14-4206     Adapting Predicate Frames for Urdu PropBanking   \n",
       "W14-4207  Measuring Language Closeness by Modeling Regul...   \n",
       "W14-4208  INVITED TALK 2: Towards Universal Syntactic Pr...   \n",
       "W14-4209  Proper Name Machine Translation from Japanese ...   \n",
       "W14-4210  Exploring cross-language statistical machine t...   \n",
       "W14-4211  Exploring System Combination approaches for In...   \n",
       "W14-4212  A Comparison of MT Methods for Closely Related...   \n",
       "W14-4213  Handling OOV Words in Dialectal Arabic to Engl...   \n",
       "\n",
       "                                                      venue  year  \n",
       "id                                                                 \n",
       "E03-1001                                               EACL  2003  \n",
       "E03-1002                                               EACL  2003  \n",
       "E03-1003                                               EACL  2003  \n",
       "E03-1004                                               EACL  2003  \n",
       "E03-1005                                               EACL  2003  \n",
       "E03-1006                                               EACL  2003  \n",
       "E03-1007                                               EACL  2003  \n",
       "E03-1008                                               EACL  2003  \n",
       "E03-1009                                               EACL  2003  \n",
       "E03-1010                                               EACL  2003  \n",
       "E03-1011                                               EACL  2003  \n",
       "E03-1012                                               EACL  2003  \n",
       "E03-1013                                               EACL  2003  \n",
       "E03-1014                                               EACL  2003  \n",
       "E03-1015                                               EACL  2003  \n",
       "E03-1017                                               EACL  2003  \n",
       "E03-1018                                               EACL  2003  \n",
       "E03-1019                                               EACL  2003  \n",
       "E03-1020                                               EACL  2003  \n",
       "E03-1021                                               EACL  2003  \n",
       "E03-1022                                               EACL  2003  \n",
       "E03-1023                                               EACL  2003  \n",
       "E03-1024                                               EACL  2003  \n",
       "E03-1025                                               EACL  2003  \n",
       "E03-1026                                               EACL  2003  \n",
       "E03-1027                                               EACL  2003  \n",
       "E03-1028                                               EACL  2003  \n",
       "E03-1029                                               EACL  2003  \n",
       "E03-1030                                               EACL  2003  \n",
       "E03-1031                                               EACL  2003  \n",
       "...                                                     ...   ...  \n",
       "W14-3912  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-3913  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-3914  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-3915  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-3916  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-3917  Workshop on Computational Approaches to Code S...  2014  \n",
       "W14-4101  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4102  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4103  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4104  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4105  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4106  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4107  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4108  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4109  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4110  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4111  Workshop on Analysis of Large Scale Social Int...  2014  \n",
       "W14-4201                                       LT4CloseLang  2014  \n",
       "W14-4202                                       LT4CloseLang  2014  \n",
       "W14-4203                                       LT4CloseLang  2014  \n",
       "W14-4204                                       LT4CloseLang  2014  \n",
       "W14-4205                                       LT4CloseLang  2014  \n",
       "W14-4206                                       LT4CloseLang  2014  \n",
       "W14-4207                                       LT4CloseLang  2014  \n",
       "W14-4208                                       LT4CloseLang  2014  \n",
       "W14-4209                                       LT4CloseLang  2014  \n",
       "W14-4210                                       LT4CloseLang  2014  \n",
       "W14-4211                                       LT4CloseLang  2014  \n",
       "W14-4212                                       LT4CloseLang  2014  \n",
       "W14-4213                                       LT4CloseLang  2014  \n",
       "\n",
       "[23766 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl.meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23595"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acl.train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 174.031s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.85, \n",
    "                                input='filename',\n",
    "                                min_df=7,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english',\n",
    "                                token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z][a-zA-Z]+\\b\",\n",
    "                                preprocessor = dehyphenate\n",
    "                                #tokenizer=TreebankWordTokenizer().tokenize\n",
    "                                )\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(acl.train_files)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "psave(tf_vectorizer,\"tf_vectozier\" + str(n_features), True)\n",
    "psave(tf,\"tf\" + str(n_features),True)\n",
    "\n",
    "# transform sparse matrix into gensim corpus\n",
    "corpus= gensim.matutils.Sparse2Corpus(tf, documents_columns=False)\n",
    "\n",
    "# transform scikit vocabulary into gensim dictionary\n",
    "vocabulary_gensim = {}\n",
    "for key, val in tf_vectorizer.vocabulary_.items():\n",
    "    vocabulary_gensim[val] = key\n",
    "    \n",
    "dic = Dictionary(tf_vectorizer.vocabulary)\n",
    "    \n",
    "psave(vocabulary_gensim,\"vocabulary\" + str(n_features),True)\n",
    "psave(corpus,\"corpus\" + str(n_features),True)\n",
    "psave(dic, \"dic\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for 20 newsgroups. \n",
    "For the 20 newsgroups dataset, we download the articles using\n",
    "the scikit-learn interface, without removing headers, footers or quotes. We parse the text using\n",
    "spaCy6\n",
    "and convert all characters to lower case. Optionally, we then exclude stopwords using the list\n",
    "of standard stopwords in Mallet. We then keep the 2000 words which appear in the largest number of\n",
    "documents.7\n",
    "\n",
    "### Preprocessing for NIPS.\n",
    "For this dataset, we use the same processing as above, except that we use\n",
    "a vocabulary size of 10,000 words, and we exclude all tokens which involve any symbols other than\n",
    "alphabetic characters, and drop all tokens of length less than 3, in order to avoid ambiguous tokens\n",
    "like section numbers and mathematical symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using symmetric alpha at 0.1\n",
      "using symmetric eta at 0.01\n",
      "using serial LDA version on this node\n",
      "running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 23595 documents, updating model once every 2000 documents, evaluating perplexity every 20000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "PROGRESS: pass 0, at document #2000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #3 (0.100): 0.050*\"semantic\" + 0.026*\"lexical\" + 0.023*\"tree\" + 0.023*\"corpus\" + 0.022*\"word\" + 0.020*\"words\" + 0.020*\"model\" + 0.020*\"parsing\" + 0.017*\"proceedings\" + 0.017*\"table\"\n",
      "topic #4 (0.100): 0.037*\"data\" + 0.029*\"semantic\" + 0.026*\"phrase\" + 0.020*\"systems\" + 0.020*\"model\" + 0.020*\"structure\" + 0.018*\"table\" + 0.018*\"evaluation\" + 0.017*\"task\" + 0.017*\"text\"\n",
      "topic #0 (0.100): 0.034*\"feature\" + 0.034*\"text\" + 0.027*\"translation\" + 0.024*\"sentence\" + 0.022*\"features\" + 0.020*\"model\" + 0.019*\"grammar\" + 0.018*\"structure\" + 0.018*\"table\" + 0.017*\"knowledge\"\n",
      "topic #5 (0.100): 0.067*\"word\" + 0.035*\"words\" + 0.029*\"model\" + 0.025*\"features\" + 0.024*\"data\" + 0.023*\"text\" + 0.022*\"sentence\" + 0.020*\"models\" + 0.018*\"proceedings\" + 0.016*\"table\"\n",
      "topic #9 (0.100): 0.033*\"tree\" + 0.031*\"rules\" + 0.027*\"grammar\" + 0.022*\"type\" + 0.021*\"figure\" + 0.021*\"word\" + 0.020*\"rule\" + 0.019*\"dependency\" + 0.019*\"words\" + 0.018*\"sentence\"\n",
      "topic diff=0.493984, rho=1.000000\n",
      "PROGRESS: pass 0, at document #4000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #7 (0.100): 0.070*\"model\" + 0.038*\"features\" + 0.035*\"training\" + 0.035*\"data\" + 0.024*\"models\" + 0.024*\"feature\" + 0.019*\"table\" + 0.019*\"algorithm\" + 0.018*\"word\" + 0.018*\"verb\"\n",
      "topic #8 (0.100): 0.046*\"discourse\" + 0.036*\"text\" + 0.036*\"relations\" + 0.029*\"relation\" + 0.027*\"sentence\" + 0.020*\"corpus\" + 0.020*\"sentences\" + 0.020*\"semantic\" + 0.018*\"type\" + 0.017*\"time\"\n",
      "topic #3 (0.100): 0.081*\"semantic\" + 0.031*\"lexical\" + 0.026*\"parsing\" + 0.025*\"parser\" + 0.023*\"tree\" + 0.021*\"word\" + 0.021*\"terms\" + 0.020*\"syntactic\" + 0.020*\"corpus\" + 0.019*\"words\"\n",
      "topic #6 (0.100): 0.048*\"sentence\" + 0.037*\"sentences\" + 0.027*\"corpus\" + 0.024*\"translation\" + 0.024*\"words\" + 0.023*\"model\" + 0.022*\"word\" + 0.021*\"text\" + 0.019*\"proceedings\" + 0.019*\"english\"\n",
      "topic #9 (0.100): 0.040*\"rules\" + 0.037*\"tree\" + 0.035*\"grammar\" + 0.029*\"rule\" + 0.025*\"parsing\" + 0.023*\"type\" + 0.021*\"structure\" + 0.021*\"figure\" + 0.021*\"dependency\" + 0.020*\"word\"\n",
      "topic diff=0.183030, rho=0.707107\n",
      "PROGRESS: pass 0, at document #6000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #2 (0.100): 0.063*\"word\" + 0.052*\"words\" + 0.049*\"sense\" + 0.039*\"similarity\" + 0.029*\"corpus\" + 0.023*\"target\" + 0.022*\"context\" + 0.021*\"lexical\" + 0.021*\"algorithm\" + 0.020*\"text\"\n",
      "topic #0 (0.100): 0.058*\"feature\" + 0.055*\"text\" + 0.040*\"features\" + 0.031*\"knowledge\" + 0.025*\"translation\" + 0.021*\"sentence\" + 0.021*\"linguistic\" + 0.020*\"structure\" + 0.019*\"level\" + 0.018*\"lexical\"\n",
      "topic #4 (0.100): 0.050*\"data\" + 0.031*\"systems\" + 0.029*\"task\" + 0.025*\"document\" + 0.024*\"evaluation\" + 0.024*\"text\" + 0.021*\"proceedings\" + 0.020*\"table\" + 0.019*\"pages\" + 0.018*\"conference\"\n",
      "topic #6 (0.100): 0.069*\"sentence\" + 0.055*\"sentences\" + 0.033*\"corpus\" + 0.024*\"words\" + 0.022*\"model\" + 0.022*\"text\" + 0.022*\"translation\" + 0.021*\"english\" + 0.020*\"proceedings\" + 0.020*\"word\"\n",
      "topic #9 (0.100): 0.046*\"rules\" + 0.040*\"grammar\" + 0.039*\"tree\" + 0.035*\"rule\" + 0.030*\"parsing\" + 0.025*\"dependency\" + 0.023*\"structure\" + 0.021*\"figure\" + 0.020*\"type\" + 0.019*\"case\"\n",
      "topic diff=0.130185, rho=0.577350\n",
      "PROGRESS: pass 0, at document #8000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #3 (0.100): 0.113*\"semantic\" + 0.038*\"lexical\" + 0.032*\"syntactic\" + 0.031*\"parser\" + 0.029*\"parsing\" + 0.026*\"terms\" + 0.020*\"word\" + 0.019*\"corpus\" + 0.019*\"words\" + 0.018*\"proceedings\"\n",
      "topic #2 (0.100): 0.071*\"word\" + 0.060*\"words\" + 0.051*\"sense\" + 0.043*\"similarity\" + 0.032*\"corpus\" + 0.026*\"context\" + 0.022*\"target\" + 0.022*\"lexical\" + 0.020*\"algorithm\" + 0.019*\"data\"\n",
      "topic #5 (0.100): 0.102*\"word\" + 0.063*\"words\" + 0.042*\"speech\" + 0.039*\"model\" + 0.028*\"features\" + 0.025*\"user\" + 0.024*\"models\" + 0.024*\"data\" + 0.022*\"text\" + 0.018*\"table\"\n",
      "topic #6 (0.100): 0.089*\"sentence\" + 0.075*\"sentences\" + 0.035*\"corpus\" + 0.024*\"words\" + 0.023*\"text\" + 0.021*\"model\" + 0.020*\"proceedings\" + 0.019*\"word\" + 0.019*\"english\" + 0.017*\"translation\"\n",
      "topic #0 (0.100): 0.065*\"text\" + 0.064*\"feature\" + 0.048*\"features\" + 0.034*\"knowledge\" + 0.024*\"linguistic\" + 0.021*\"lexical\" + 0.020*\"structure\" + 0.020*\"level\" + 0.019*\"translation\" + 0.019*\"sentence\"\n",
      "topic diff=0.099525, rho=0.500000\n",
      "PROGRESS: pass 0, at document #10000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #2 (0.100): 0.077*\"word\" + 0.066*\"words\" + 0.049*\"sense\" + 0.048*\"similarity\" + 0.033*\"corpus\" + 0.028*\"context\" + 0.022*\"target\" + 0.021*\"lexical\" + 0.021*\"algorithm\" + 0.019*\"pairs\"\n",
      "topic #0 (0.100): 0.070*\"feature\" + 0.069*\"text\" + 0.054*\"features\" + 0.038*\"knowledge\" + 0.028*\"linguistic\" + 0.022*\"level\" + 0.022*\"lexical\" + 0.021*\"structure\" + 0.016*\"sentence\" + 0.015*\"domain\"\n",
      "topic #8 (0.100): 0.072*\"discourse\" + 0.055*\"relations\" + 0.055*\"relation\" + 0.037*\"text\" + 0.024*\"sentence\" + 0.023*\"structure\" + 0.022*\"type\" + 0.020*\"corpus\" + 0.019*\"time\" + 0.018*\"knowledge\"\n",
      "topic #5 (0.100): 0.113*\"word\" + 0.073*\"words\" + 0.046*\"speech\" + 0.041*\"model\" + 0.025*\"features\" + 0.024*\"data\" + 0.024*\"models\" + 0.022*\"user\" + 0.021*\"text\" + 0.018*\"table\"\n",
      "topic #6 (0.100): 0.108*\"sentence\" + 0.089*\"sentences\" + 0.036*\"corpus\" + 0.024*\"words\" + 0.023*\"text\" + 0.020*\"model\" + 0.020*\"proceedings\" + 0.019*\"english\" + 0.018*\"word\" + 0.017*\"pairs\"\n",
      "topic diff=0.083455, rho=0.447214\n",
      "PROGRESS: pass 0, at document #12000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #1 (0.100): 0.095*\"translation\" + 0.044*\"word\" + 0.041*\"english\" + 0.033*\"model\" + 0.033*\"data\" + 0.031*\"source\" + 0.030*\"machine\" + 0.030*\"words\" + 0.025*\"phrase\" + 0.025*\"target\"\n",
      "topic #6 (0.100): 0.122*\"sentence\" + 0.102*\"sentences\" + 0.036*\"corpus\" + 0.024*\"words\" + 0.023*\"text\" + 0.020*\"proceedings\" + 0.018*\"model\" + 0.017*\"english\" + 0.017*\"word\" + 0.016*\"pairs\"\n",
      "topic #2 (0.100): 0.081*\"word\" + 0.068*\"words\" + 0.053*\"similarity\" + 0.051*\"sense\" + 0.033*\"corpus\" + 0.028*\"context\" + 0.021*\"lexical\" + 0.021*\"target\" + 0.021*\"algorithm\" + 0.019*\"pairs\"\n",
      "topic #4 (0.100): 0.056*\"data\" + 0.034*\"systems\" + 0.033*\"task\" + 0.033*\"document\" + 0.031*\"user\" + 0.028*\"evaluation\" + 0.027*\"text\" + 0.023*\"proceedings\" + 0.021*\"pages\" + 0.021*\"table\"\n",
      "topic #8 (0.100): 0.081*\"discourse\" + 0.062*\"relations\" + 0.061*\"relation\" + 0.034*\"text\" + 0.026*\"structure\" + 0.022*\"sentence\" + 0.022*\"type\" + 0.018*\"time\" + 0.018*\"corpus\" + 0.018*\"knowledge\"\n",
      "topic diff=0.071268, rho=0.408248\n",
      "PROGRESS: pass 0, at document #14000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #1 (0.100): 0.098*\"translation\" + 0.043*\"english\" + 0.043*\"word\" + 0.035*\"model\" + 0.034*\"source\" + 0.033*\"data\" + 0.032*\"machine\" + 0.028*\"phrase\" + 0.028*\"words\" + 0.028*\"target\"\n",
      "topic #6 (0.100): 0.133*\"sentence\" + 0.112*\"sentences\" + 0.038*\"corpus\" + 0.024*\"text\" + 0.024*\"words\" + 0.020*\"proceedings\" + 0.017*\"model\" + 0.016*\"english\" + 0.016*\"table\" + 0.016*\"word\"\n",
      "topic #0 (0.100): 0.079*\"text\" + 0.073*\"feature\" + 0.064*\"features\" + 0.043*\"knowledge\" + 0.029*\"linguistic\" + 0.026*\"level\" + 0.024*\"lexical\" + 0.020*\"structure\" + 0.018*\"type\" + 0.018*\"analysis\"\n",
      "topic #4 (0.100): 0.056*\"data\" + 0.035*\"systems\" + 0.034*\"document\" + 0.034*\"task\" + 0.033*\"user\" + 0.029*\"evaluation\" + 0.028*\"text\" + 0.023*\"proceedings\" + 0.021*\"pages\" + 0.021*\"figure\"\n",
      "topic #5 (0.100): 0.127*\"word\" + 0.081*\"words\" + 0.060*\"speech\" + 0.044*\"model\" + 0.025*\"data\" + 0.024*\"models\" + 0.020*\"features\" + 0.019*\"text\" + 0.019*\"corpus\" + 0.018*\"table\"\n",
      "topic diff=0.059716, rho=0.377964\n",
      "PROGRESS: pass 0, at document #16000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #6 (0.100): 0.144*\"sentence\" + 0.117*\"sentences\" + 0.038*\"corpus\" + 0.025*\"text\" + 0.023*\"words\" + 0.020*\"proceedings\" + 0.016*\"evaluation\" + 0.016*\"table\" + 0.016*\"english\" + 0.016*\"model\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic #1 (0.100): 0.105*\"translation\" + 0.046*\"english\" + 0.040*\"word\" + 0.036*\"model\" + 0.036*\"source\" + 0.034*\"machine\" + 0.030*\"data\" + 0.030*\"phrase\" + 0.029*\"target\" + 0.027*\"words\"\n",
      "topic #0 (0.100): 0.083*\"text\" + 0.071*\"feature\" + 0.065*\"features\" + 0.044*\"knowledge\" + 0.032*\"linguistic\" + 0.027*\"level\" + 0.024*\"lexical\" + 0.020*\"structure\" + 0.019*\"analysis\" + 0.018*\"type\"\n",
      "topic #2 (0.100): 0.083*\"word\" + 0.070*\"words\" + 0.055*\"similarity\" + 0.053*\"sense\" + 0.034*\"corpus\" + 0.031*\"context\" + 0.022*\"method\" + 0.021*\"target\" + 0.021*\"pairs\" + 0.020*\"lexical\"\n",
      "topic #8 (0.100): 0.080*\"discourse\" + 0.073*\"relations\" + 0.073*\"relation\" + 0.032*\"text\" + 0.027*\"structure\" + 0.024*\"type\" + 0.020*\"sentence\" + 0.019*\"time\" + 0.018*\"knowledge\" + 0.017*\"corpus\"\n",
      "topic diff=0.055122, rho=0.353553\n",
      "PROGRESS: pass 0, at document #18000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #5 (0.100): 0.136*\"word\" + 0.092*\"words\" + 0.068*\"speech\" + 0.045*\"model\" + 0.025*\"models\" + 0.024*\"data\" + 0.021*\"corpus\" + 0.019*\"table\" + 0.019*\"text\" + 0.016*\"features\"\n",
      "topic #3 (0.100): 0.148*\"semantic\" + 0.054*\"syntactic\" + 0.044*\"lexical\" + 0.037*\"verb\" + 0.026*\"parser\" + 0.026*\"noun\" + 0.022*\"terms\" + 0.022*\"parsing\" + 0.018*\"word\" + 0.017*\"corpus\"\n",
      "topic #6 (0.100): 0.154*\"sentence\" + 0.122*\"sentences\" + 0.039*\"corpus\" + 0.025*\"text\" + 0.023*\"words\" + 0.019*\"proceedings\" + 0.016*\"table\" + 0.016*\"evaluation\" + 0.016*\"english\" + 0.015*\"word\"\n",
      "topic #8 (0.100): 0.085*\"discourse\" + 0.077*\"relations\" + 0.076*\"relation\" + 0.031*\"text\" + 0.029*\"structure\" + 0.026*\"type\" + 0.019*\"sentence\" + 0.019*\"time\" + 0.018*\"knowledge\" + 0.017*\"corpus\"\n",
      "topic #7 (0.100): 0.083*\"model\" + 0.062*\"features\" + 0.053*\"training\" + 0.048*\"data\" + 0.039*\"models\" + 0.037*\"learning\" + 0.033*\"feature\" + 0.023*\"table\" + 0.023*\"performance\" + 0.022*\"proceedings\"\n",
      "topic diff=0.048333, rho=0.333333\n",
      "-4.285 per-word bound, 19.5 perplexity estimate based on a held-out corpus of 2000 documents with 821624 words\n",
      "PROGRESS: pass 0, at document #20000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #4 (0.100): 0.053*\"data\" + 0.041*\"user\" + 0.038*\"document\" + 0.036*\"task\" + 0.035*\"systems\" + 0.029*\"evaluation\" + 0.029*\"text\" + 0.024*\"proceedings\" + 0.022*\"pages\" + 0.022*\"figure\"\n",
      "topic #0 (0.100): 0.083*\"text\" + 0.071*\"feature\" + 0.068*\"features\" + 0.046*\"knowledge\" + 0.035*\"linguistic\" + 0.028*\"level\" + 0.025*\"lexical\" + 0.021*\"type\" + 0.021*\"analysis\" + 0.020*\"structure\"\n",
      "topic #6 (0.100): 0.159*\"sentence\" + 0.125*\"sentences\" + 0.040*\"corpus\" + 0.026*\"text\" + 0.023*\"words\" + 0.019*\"proceedings\" + 0.016*\"table\" + 0.016*\"evaluation\" + 0.015*\"score\" + 0.015*\"method\"\n",
      "topic #8 (0.100): 0.088*\"discourse\" + 0.081*\"relation\" + 0.079*\"relations\" + 0.030*\"text\" + 0.029*\"structure\" + 0.027*\"type\" + 0.019*\"sentence\" + 0.018*\"knowledge\" + 0.018*\"time\" + 0.018*\"types\"\n",
      "topic #2 (0.100): 0.085*\"word\" + 0.072*\"words\" + 0.056*\"similarity\" + 0.055*\"sense\" + 0.036*\"corpus\" + 0.032*\"context\" + 0.026*\"method\" + 0.022*\"pairs\" + 0.021*\"target\" + 0.020*\"algorithm\"\n",
      "topic diff=0.044868, rho=0.316228\n",
      "PROGRESS: pass 0, at document #22000/23595\n",
      "merging changes from 2000 documents into a model of 23595 documents\n",
      "topic #6 (0.100): 0.164*\"sentence\" + 0.129*\"sentences\" + 0.041*\"corpus\" + 0.026*\"text\" + 0.022*\"words\" + 0.019*\"proceedings\" + 0.017*\"table\" + 0.016*\"evaluation\" + 0.016*\"score\" + 0.015*\"method\"\n",
      "topic #1 (0.100): 0.116*\"translation\" + 0.054*\"english\" + 0.039*\"source\" + 0.038*\"word\" + 0.037*\"machine\" + 0.037*\"model\" + 0.033*\"phrase\" + 0.032*\"target\" + 0.027*\"data\" + 0.024*\"statistical\"\n",
      "topic #3 (0.100): 0.146*\"semantic\" + 0.056*\"syntactic\" + 0.052*\"verb\" + 0.046*\"lexical\" + 0.035*\"noun\" + 0.022*\"parser\" + 0.020*\"terms\" + 0.019*\"parsing\" + 0.018*\"corpus\" + 0.017*\"word\"\n",
      "topic #4 (0.100): 0.052*\"data\" + 0.044*\"user\" + 0.038*\"document\" + 0.036*\"systems\" + 0.035*\"task\" + 0.030*\"evaluation\" + 0.029*\"text\" + 0.024*\"proceedings\" + 0.022*\"figure\" + 0.022*\"pages\"\n",
      "topic #8 (0.100): 0.091*\"discourse\" + 0.083*\"relations\" + 0.082*\"relation\" + 0.032*\"structure\" + 0.029*\"text\" + 0.027*\"type\" + 0.021*\"time\" + 0.019*\"knowledge\" + 0.018*\"types\" + 0.017*\"sentence\"\n",
      "topic diff=0.042175, rho=0.301511\n",
      "-4.267 per-word bound, 19.2 perplexity estimate based on a held-out corpus of 1595 documents with 663498 words\n",
      "PROGRESS: pass 0, at document #23595/23595\n",
      "merging changes from 1595 documents into a model of 23595 documents\n",
      "topic #3 (0.100): 0.151*\"semantic\" + 0.057*\"syntactic\" + 0.053*\"verb\" + 0.046*\"lexical\" + 0.037*\"noun\" + 0.022*\"parser\" + 0.020*\"terms\" + 0.018*\"corpus\" + 0.018*\"parsing\" + 0.016*\"proceedings\"\n",
      "topic #9 (0.100): 0.057*\"grammar\" + 0.057*\"rules\" + 0.052*\"tree\" + 0.045*\"parsing\" + 0.045*\"rule\" + 0.029*\"structure\" + 0.027*\"parser\" + 0.026*\"case\" + 0.025*\"dependency\" + 0.024*\"figure\"\n",
      "topic #5 (0.100): 0.149*\"word\" + 0.103*\"words\" + 0.069*\"speech\" + 0.050*\"model\" + 0.025*\"models\" + 0.024*\"corpus\" + 0.024*\"data\" + 0.019*\"table\" + 0.017*\"text\" + 0.016*\"training\"\n",
      "topic #4 (0.100): 0.053*\"data\" + 0.043*\"user\" + 0.039*\"document\" + 0.036*\"systems\" + 0.036*\"task\" + 0.029*\"text\" + 0.029*\"evaluation\" + 0.024*\"proceedings\" + 0.022*\"figure\" + 0.022*\"pages\"\n",
      "topic #6 (0.100): 0.169*\"sentence\" + 0.134*\"sentences\" + 0.043*\"corpus\" + 0.026*\"text\" + 0.022*\"words\" + 0.019*\"proceedings\" + 0.017*\"table\" + 0.017*\"evaluation\" + 0.016*\"score\" + 0.016*\"method\"\n",
      "topic diff=0.040301, rho=0.288675\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus, num_topics=100, id2word=vocabulary_gensim, passes=50)\n",
    "psave(lda_model, \"ldamodel-\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../models/ldamodel2017-11-04 03_49_52\",\"rb\") as f:\n",
    "#     lda_model = pkl.load(f)\n",
    "\n",
    "# with open(\"../models/corpus600002017-11-03 22_37_14\",\"rb\") as f:\n",
    "#     corpus = pkl.load(f)\n",
    "\n",
    "# with open(\"../models/dic2017-11-03 22_37_15\",\"rb\") as f:\n",
    "#     dic = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.081*\"text\" + 0.071*\"feature\" + 0.069*\"features\" + 0.048*\"knowledge\" + 0.037*\"linguistic\" + 0.029*\"level\" + 0.026*\"lexical\" + 0.024*\"type\" + 0.022*\"analysis\" + 0.021*\"domain\"'),\n",
       " (1,\n",
       "  '0.117*\"translation\" + 0.058*\"english\" + 0.040*\"source\" + 0.037*\"machine\" + 0.037*\"word\" + 0.037*\"model\" + 0.033*\"phrase\" + 0.033*\"target\" + 0.027*\"data\" + 0.024*\"statistical\"'),\n",
       " (2,\n",
       "  '0.086*\"word\" + 0.074*\"words\" + 0.059*\"similarity\" + 0.054*\"sense\" + 0.036*\"corpus\" + 0.031*\"context\" + 0.029*\"method\" + 0.024*\"pairs\" + 0.021*\"algorithm\" + 0.020*\"table\"'),\n",
       " (3,\n",
       "  '0.151*\"semantic\" + 0.057*\"syntactic\" + 0.053*\"verb\" + 0.046*\"lexical\" + 0.037*\"noun\" + 0.022*\"parser\" + 0.020*\"terms\" + 0.018*\"corpus\" + 0.018*\"parsing\" + 0.016*\"proceedings\"'),\n",
       " (4,\n",
       "  '0.053*\"data\" + 0.043*\"user\" + 0.039*\"document\" + 0.036*\"systems\" + 0.036*\"task\" + 0.029*\"text\" + 0.029*\"evaluation\" + 0.024*\"proceedings\" + 0.022*\"figure\" + 0.022*\"pages\"'),\n",
       " (5,\n",
       "  '0.149*\"word\" + 0.103*\"words\" + 0.069*\"speech\" + 0.050*\"model\" + 0.025*\"models\" + 0.024*\"corpus\" + 0.024*\"data\" + 0.019*\"table\" + 0.017*\"text\" + 0.016*\"training\"'),\n",
       " (6,\n",
       "  '0.169*\"sentence\" + 0.134*\"sentences\" + 0.043*\"corpus\" + 0.026*\"text\" + 0.022*\"words\" + 0.019*\"proceedings\" + 0.017*\"table\" + 0.017*\"evaluation\" + 0.016*\"score\" + 0.016*\"method\"'),\n",
       " (7,\n",
       "  '0.085*\"model\" + 0.061*\"features\" + 0.057*\"training\" + 0.052*\"data\" + 0.042*\"learning\" + 0.040*\"models\" + 0.032*\"feature\" + 0.024*\"table\" + 0.024*\"performance\" + 0.022*\"proceedings\"'),\n",
       " (8,\n",
       "  '0.093*\"discourse\" + 0.085*\"relations\" + 0.085*\"relation\" + 0.032*\"structure\" + 0.029*\"text\" + 0.028*\"type\" + 0.020*\"time\" + 0.019*\"knowledge\" + 0.018*\"types\" + 0.017*\"sentence\"'),\n",
       " (9,\n",
       "  '0.057*\"grammar\" + 0.057*\"rules\" + 0.052*\"tree\" + 0.045*\"parsing\" + 0.045*\"rule\" + 0.029*\"structure\" + 0.027*\"parser\" + 0.026*\"case\" + 0.025*\"dependency\" + 0.024*\"figure\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.show_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "pyLDAvis.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "data = pyLDAvis.gensim.prepare(lda_model, corpus, dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
